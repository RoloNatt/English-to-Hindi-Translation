{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoloNatt/English-to-Hindi-Translation/blob/main/English_to_Hindi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcPgcMjURhqJ",
        "outputId": "2992b733-9bec-4b8e-e48e-819d971eba17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-096836cbf52f>:16: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  pd.set_option('display.max_colwidth', -1)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense,TimeDistributed,Embedding,Bidirectional\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from string import digits\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_colwidth', -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TbSCNE3ZSSjO"
      },
      "outputs": [],
      "source": [
        "lines = pd.read_csv('small_data.csv')\n",
        "lines = lines[:5000]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fc0I8ghDeOoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NpiM3T5-Y_j0",
        "outputId": "24241e56-17f5-4c18-fc04-212f9356b62d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                               hindi                                                                                             english\n",
              "0  तो लघुतम संपवर्तक होगा—क्यूंकी इन                                                  So the least common multiple is going to be - - because these                                     \n",
              "1  इब्राहिम ने कहा क्या मुझे ख़ुशख़बरी (बेटा होने की) देते हो जब मुझे बुढ़ापा छा गया  He said, “Do you bring me good news, when old age has overtaken me? What good news do you bring? ”\n",
              "2  प्रयोग के लिए इकाई जब तापमान दिखाया जा रहा हो.                                     The unit to use when showing temperatures.                                                        \n",
              "3  और जिन्हें तुम पूजते हो मैं उनका पूजने वाला नहीं                                   Nor am I worshiping what you have worshipped,                                                     \n",
              "4  सिनसिनाटी मास्टर्स                                                                 1989 Cincinnati Open 1989                                                                         "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0357ad3-1774-4136-adf7-689f0ac88017\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hindi</th>\n",
              "      <th>english</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>तो लघुतम संपवर्तक होगा—क्यूंकी इन</td>\n",
              "      <td>So the least common multiple is going to be - - because these</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>इब्राहिम ने कहा क्या मुझे ख़ुशख़बरी (बेटा होने की) देते हो जब मुझे बुढ़ापा छा गया</td>\n",
              "      <td>He said, “Do you bring me good news, when old age has overtaken me? What good news do you bring? ”</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>प्रयोग के लिए इकाई जब तापमान दिखाया जा रहा हो.</td>\n",
              "      <td>The unit to use when showing temperatures.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>और जिन्हें तुम पूजते हो मैं उनका पूजने वाला नहीं</td>\n",
              "      <td>Nor am I worshiping what you have worshipped,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>सिनसिनाटी मास्टर्स</td>\n",
              "      <td>1989 Cincinnati Open 1989</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0357ad3-1774-4136-adf7-689f0ac88017')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c0357ad3-1774-4136-adf7-689f0ac88017 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c0357ad3-1774-4136-adf7-689f0ac88017');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c948c0a2-fb6c-4e9d-99c5-98a9878555fb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c948c0a2-fb6c-4e9d-99c5-98a9878555fb')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c948c0a2-fb6c-4e9d-99c5-98a9878555fb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "lines.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "or2y6K12ZBaT"
      },
      "outputs": [],
      "source": [
        "lines['english']=lines['english'].apply(lambda x: str(x))\n",
        "lines['hindi']=lines['hindi'].apply(lambda x: str(x))\n",
        "lines['english']=lines['english'].apply(lambda x: x.lower())\n",
        "lines['hindi']=lines['hindi'].apply(lambda x: x.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kBE7TYBaZCb3",
        "outputId": "441fe39a-7ae5-4375-e2fa-255f3fc99e39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'तो लघुतम संपवर्तक होगा—क्यूंकी इन'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "lines['hindi'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KKpHkmsQZEJz"
      },
      "outputs": [],
      "source": [
        "# Remove quotes\n",
        "lines['english']=lines['english'].apply(lambda x: re.sub(\"'\", '', x))\n",
        "lines['hindi']=lines['hindi'].apply(lambda x: re.sub(\"'\", '', x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pLkIHS8QZJJQ",
        "outputId": "a565a384-7b73-4804-af4e-a8194a95b0ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                               hindi                                                                                             english\n",
              "0  तो लघुतम संपवर्तक होगा—क्यूंकी इन                                                  so the least common multiple is going to be - - because these                                     \n",
              "1  इब्राहिम ने कहा क्या मुझे ख़ुशख़बरी (बेटा होने की) देते हो जब मुझे बुढ़ापा छा गया  he said, “do you bring me good news, when old age has overtaken me? what good news do you bring? ”\n",
              "2  प्रयोग के लिए इकाई जब तापमान दिखाया जा रहा हो.                                     the unit to use when showing temperatures.                                                        \n",
              "3  और जिन्हें तुम पूजते हो मैं उनका पूजने वाला नहीं                                   nor am i worshiping what you have worshipped,                                                     \n",
              "4  सिनसिनाटी मास्टर्स                                                                 1989 cincinnati open 1989                                                                         "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca31d0b4-6ee0-4caa-8a6d-b6af9cade800\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hindi</th>\n",
              "      <th>english</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>तो लघुतम संपवर्तक होगा—क्यूंकी इन</td>\n",
              "      <td>so the least common multiple is going to be - - because these</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>इब्राहिम ने कहा क्या मुझे ख़ुशख़बरी (बेटा होने की) देते हो जब मुझे बुढ़ापा छा गया</td>\n",
              "      <td>he said, “do you bring me good news, when old age has overtaken me? what good news do you bring? ”</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>प्रयोग के लिए इकाई जब तापमान दिखाया जा रहा हो.</td>\n",
              "      <td>the unit to use when showing temperatures.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>और जिन्हें तुम पूजते हो मैं उनका पूजने वाला नहीं</td>\n",
              "      <td>nor am i worshiping what you have worshipped,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>सिनसिनाटी मास्टर्स</td>\n",
              "      <td>1989 cincinnati open 1989</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca31d0b4-6ee0-4caa-8a6d-b6af9cade800')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ca31d0b4-6ee0-4caa-8a6d-b6af9cade800 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ca31d0b4-6ee0-4caa-8a6d-b6af9cade800');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-10c6e030-1f9e-421e-90e0-fe872301e5df\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-10c6e030-1f9e-421e-90e0-fe872301e5df')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-10c6e030-1f9e-421e-90e0-fe872301e5df button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "lines.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1539WdmFZLsI"
      },
      "outputs": [],
      "source": [
        "exclude = set(string.punctuation) # Set of all special characters\n",
        "# Remove all the special characters\n",
        "lines['english']=lines['english'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "lines['hindi']=lines['hindi'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ozWfGdrQZM9d",
        "outputId": "1d0ec1e6-9085-43e9-b0cc-9c1ac3769f16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                             hindi                                                                                         english\n",
              "0  तो लघुतम संपवर्तक होगा—क्यूंकी इन                                                so the least common multiple is going to be   because these                                   \n",
              "1  इब्राहिम ने कहा क्या मुझे ख़ुशख़बरी बेटा होने की देते हो जब मुझे बुढ़ापा छा गया  he said “do you bring me good news when old age has overtaken me what good news do you bring ”\n",
              "2  प्रयोग के लिए इकाई जब तापमान दिखाया जा रहा हो                                    the unit to use when showing temperatures                                                     \n",
              "3  और जिन्हें तुम पूजते हो मैं उनका पूजने वाला नहीं                                 nor am i worshiping what you have worshipped                                                  \n",
              "4  सिनसिनाटी मास्टर्स                                                               1989 cincinnati open 1989                                                                     "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b578d8e4-b99a-4ea3-8bb3-1d740897ce83\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hindi</th>\n",
              "      <th>english</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>तो लघुतम संपवर्तक होगा—क्यूंकी इन</td>\n",
              "      <td>so the least common multiple is going to be   because these</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>इब्राहिम ने कहा क्या मुझे ख़ुशख़बरी बेटा होने की देते हो जब मुझे बुढ़ापा छा गया</td>\n",
              "      <td>he said “do you bring me good news when old age has overtaken me what good news do you bring ”</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>प्रयोग के लिए इकाई जब तापमान दिखाया जा रहा हो</td>\n",
              "      <td>the unit to use when showing temperatures</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>और जिन्हें तुम पूजते हो मैं उनका पूजने वाला नहीं</td>\n",
              "      <td>nor am i worshiping what you have worshipped</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>सिनसिनाटी मास्टर्स</td>\n",
              "      <td>1989 cincinnati open 1989</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b578d8e4-b99a-4ea3-8bb3-1d740897ce83')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b578d8e4-b99a-4ea3-8bb3-1d740897ce83 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b578d8e4-b99a-4ea3-8bb3-1d740897ce83');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3afacb5c-2020-47fa-807d-d5372f7bd9e0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3afacb5c-2020-47fa-807d-d5372f7bd9e0')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3afacb5c-2020-47fa-807d-d5372f7bd9e0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "lines.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lHsvvSKtZObm"
      },
      "outputs": [],
      "source": [
        "remove_digits = str.maketrans('', '', digits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRrOqiHyZP6Y",
        "outputId": "1a9fbd8a-9452-40c1-94b4-91916d1950e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{48: None,\n",
              " 49: None,\n",
              " 50: None,\n",
              " 51: None,\n",
              " 52: None,\n",
              " 53: None,\n",
              " 54: None,\n",
              " 55: None,\n",
              " 56: None,\n",
              " 57: None}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "remove_digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ImyFTsC5ZRJU"
      },
      "outputs": [],
      "source": [
        "a = lines['english'][0].translate(remove_digits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "b_PF9Qz8ZSob",
        "outputId": "cc6793be-8bbc-4e91-9524-66e807a4fe4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'so the least common multiple is going to be   because these'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IS4KGnnIZTjh",
        "outputId": "2f7e3e7f-ef8c-44b8-f67c-19bd3dbfcbfb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'so the least common multiple is going to be   because these'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "a.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nMJhLCZyZU8x"
      },
      "outputs": [],
      "source": [
        "# Remove all numbers from text\n",
        "remove_digits = str.maketrans('', '', digits)\n",
        "lines['english']=lines['english'].apply(lambda x: x.translate(remove_digits))\n",
        "lines['hindi']=lines['hindi'].apply(lambda x: x.translate(remove_digits))\n",
        "\n",
        "lines['hindi'] = lines['hindi'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
        "\n",
        "# Remove extra spaces\n",
        "lines['english']=lines['english'].apply(lambda x: x.strip())\n",
        "lines['hindi']=lines['hindi'].apply(lambda x: x.strip())\n",
        "lines['english']=lines['english'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "lines['hindi']=lines['hindi'].apply(lambda x: re.sub(\" +\", \" \", x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "K8pcGJDNZXKD",
        "outputId": "fffe37d3-b020-4860-b125-34e3c97de782"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'so the least common multiple is going to be because these'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "lines['english'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DoP-hfdzZYko"
      },
      "outputs": [],
      "source": [
        "# Add start and end tokens to target sequences\n",
        "lines['hindi'] = lines['hindi'].apply(lambda x : 'START_ '+ x + ' _END')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gu2MxBNSZZqH",
        "outputId": "892c2702-8397-47cd-c20b-58b8e2bfc815"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'START_ तो लघुतम संपवर्तक होगा—क्यूंकी इन _END'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "lines['hindi'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9oAuA-7KZasF"
      },
      "outputs": [],
      "source": [
        "### Get English and Hindi Vocabulary\n",
        "all_eng_words=set()\n",
        "for eng in lines['english']:\n",
        "    for word in eng.split():\n",
        "        if word not in all_eng_words:\n",
        "            all_eng_words.add(word)\n",
        "\n",
        "all_hindi_words=set()\n",
        "for hin in lines['hindi']:\n",
        "    for word in hin.split():\n",
        "        if word not in all_hindi_words:\n",
        "            all_hindi_words.add(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BgEyVGzYZePD",
        "outputId": "ca349402-1e29-435e-db4c-59c071f0aec7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                         hindi                                                                                         english\n",
              "0  START_ तो लघुतम संपवर्तक होगा—क्यूंकी इन _END                                                so the least common multiple is going to be because these                                     \n",
              "1  START_ इब्राहिम ने कहा क्या मुझे ख़ुशख़बरी बेटा होने की देते हो जब मुझे बुढ़ापा छा गया _END  he said “do you bring me good news when old age has overtaken me what good news do you bring ”\n",
              "2  START_ प्रयोग के लिए इकाई जब तापमान दिखाया जा रहा हो _END                                    the unit to use when showing temperatures                                                     \n",
              "3  START_ और जिन्हें तुम पूजते हो मैं उनका पूजने वाला नहीं _END                                 nor am i worshiping what you have worshipped                                                  \n",
              "4  START_ सिनसिनाटी मास्टर्स _END                                                               cincinnati open                                                                               "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-374c6362-482c-42c9-b8ca-4524504bc656\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hindi</th>\n",
              "      <th>english</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>START_ तो लघुतम संपवर्तक होगा—क्यूंकी इन _END</td>\n",
              "      <td>so the least common multiple is going to be because these</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>START_ इब्राहिम ने कहा क्या मुझे ख़ुशख़बरी बेटा होने की देते हो जब मुझे बुढ़ापा छा गया _END</td>\n",
              "      <td>he said “do you bring me good news when old age has overtaken me what good news do you bring ”</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>START_ प्रयोग के लिए इकाई जब तापमान दिखाया जा रहा हो _END</td>\n",
              "      <td>the unit to use when showing temperatures</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>START_ और जिन्हें तुम पूजते हो मैं उनका पूजने वाला नहीं _END</td>\n",
              "      <td>nor am i worshiping what you have worshipped</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>START_ सिनसिनाटी मास्टर्स _END</td>\n",
              "      <td>cincinnati open</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-374c6362-482c-42c9-b8ca-4524504bc656')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-374c6362-482c-42c9-b8ca-4524504bc656 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-374c6362-482c-42c9-b8ca-4524504bc656');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7c9bc451-9bf8-46a2-a99d-87d423fe3d86\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7c9bc451-9bf8-46a2-a99d-87d423fe3d86')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7c9bc451-9bf8-46a2-a99d-87d423fe3d86 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "lines.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "bvneFF13ZfZo"
      },
      "outputs": [],
      "source": [
        "lines['length_eng']=lines['english'].apply(lambda x:len(x.split(\" \")))\n",
        "lines['length_hin']=lines['hindi'].apply(lambda x:len(x.split(\" \")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlPshr1XZgqa",
        "outputId": "899a3207-df30-4430-996e-778839a02ead"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(450, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "lines.head()\n",
        "lines[lines['length_eng']>30].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "zjWqchOXZh7e"
      },
      "outputs": [],
      "source": [
        "lines=lines[lines['length_eng']<=20]\n",
        "lines=lines[lines['length_hin']<=20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Y9_wQ6BZjRp",
        "outputId": "012d9d81-da31-4635-8632-877730b4d821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maximum length of Hindi Sentence  20\n",
            "maximum length of English Sentence  20\n"
          ]
        }
      ],
      "source": [
        "print(\"maximum length of Hindi Sentence \",max(lines['length_hin']))\n",
        "print(\"maximum length of English Sentence \",max(lines['length_eng']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "uQbKH9VWZk0m"
      },
      "outputs": [],
      "source": [
        "max_length_src=max(lines['length_hin'])\n",
        "max_length_tar=max(lines['length_eng'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGvvjw39ZmCu",
        "outputId": "f9c9ad82-d169-4117-b6d0-70ac111c6e36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11026, 13227)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "input_words = sorted(list(all_eng_words))\n",
        "target_words = sorted(list(all_hindi_words))\n",
        "num_encoder_tokens = len(all_eng_words)\n",
        "num_decoder_tokens = len(all_hindi_words)\n",
        "num_encoder_tokens, num_decoder_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDK7Z1DJZnFf",
        "outputId": "0903fbd6-fb5d-4588-f31c-46ef78f0e1f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13227"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "num_decoder_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "I2R1SUaEZoN1"
      },
      "outputs": [],
      "source": [
        "num_decoder_tokens += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCki52x7Zpkf",
        "outputId": "d44208cc-1fbf-496f-956f-9ca162ba1204"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13228"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "num_decoder_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "_fnQm4NPZrUq"
      },
      "outputs": [],
      "source": [
        "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nngzlnbHZsjg",
        "outputId": "a9227b2f-3405-44ac-e67e-ee5045bcd42f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': 1,\n",
              " 'aa': 2,\n",
              " 'aakashdeep': 3,\n",
              " 'aampapad': 4,\n",
              " 'aaron': 5,\n",
              " 'aastuny': 6,\n",
              " 'abandon': 7,\n",
              " 'abase': 8,\n",
              " 'abasements': 9,\n",
              " 'abated': 10,\n",
              " 'abating': 11,\n",
              " 'abdel': 12,\n",
              " 'abdul': 13,\n",
              " 'abhi': 14,\n",
              " 'abhinav': 15,\n",
              " 'abide': 16,\n",
              " 'abiding': 17,\n",
              " 'abidjan': 18,\n",
              " 'ability': 19,\n",
              " 'abiword': 20,\n",
              " 'able': 21,\n",
              " 'abnormal': 22,\n",
              " 'abnormally': 23,\n",
              " 'abode': 24,\n",
              " 'abomination': 25,\n",
              " 'about': 26,\n",
              " 'above': 27,\n",
              " 'abraham': 28,\n",
              " 'abroad': 29,\n",
              " 'abruptly': 30,\n",
              " 'abscess': 31,\n",
              " 'absence': 32,\n",
              " 'absent': 33,\n",
              " 'absents': 34,\n",
              " 'absolute': 35,\n",
              " 'absolutely': 36,\n",
              " 'absolution': 37,\n",
              " 'absorb': 38,\n",
              " 'absorbed': 39,\n",
              " 'abstract': 40,\n",
              " 'absurd': 41,\n",
              " 'abtar': 42,\n",
              " 'abu': 43,\n",
              " 'abundant': 44,\n",
              " 'abuse': 45,\n",
              " 'academic': 46,\n",
              " 'academics': 47,\n",
              " 'academy': 48,\n",
              " 'acceded': 49,\n",
              " 'accentuation': 50,\n",
              " 'accept': 51,\n",
              " 'acceptable': 52,\n",
              " 'acceptance': 53,\n",
              " 'accepted': 54,\n",
              " 'accepting': 55,\n",
              " 'accepts': 56,\n",
              " 'access': 57,\n",
              " 'accessed': 58,\n",
              " 'accessibility': 59,\n",
              " 'accessing': 60,\n",
              " 'accident': 61,\n",
              " 'accidents': 62,\n",
              " 'accompanied': 63,\n",
              " 'accompaniment': 64,\n",
              " 'accompany': 65,\n",
              " 'accomplish': 66,\n",
              " 'accomplishment': 67,\n",
              " 'accord': 68,\n",
              " 'accordance': 69,\n",
              " 'accorded': 70,\n",
              " 'according': 71,\n",
              " 'accordingly': 72,\n",
              " 'account': 73,\n",
              " 'accountability': 74,\n",
              " 'accountant': 75,\n",
              " 'accounting': 76,\n",
              " 'accounts': 77,\n",
              " 'accredited': 78,\n",
              " 'accrue': 79,\n",
              " 'accumulated': 80,\n",
              " 'accurate': 81,\n",
              " 'accused': 82,\n",
              " 'ace': 83,\n",
              " 'aceh': 84,\n",
              " 'acharya': 85,\n",
              " 'achieve': 86,\n",
              " 'achieved': 87,\n",
              " 'achievement': 88,\n",
              " 'achievements': 89,\n",
              " 'achievers': 90,\n",
              " 'acid': 91,\n",
              " 'acidic': 92,\n",
              " 'acids': 93,\n",
              " 'acids葉ransfer': 94,\n",
              " 'acknowledged': 95,\n",
              " 'acknowledges': 96,\n",
              " 'aclean': 97,\n",
              " 'acquainted': 98,\n",
              " 'acquiesced': 99,\n",
              " 'acquire': 100,\n",
              " 'acquired': 101,\n",
              " 'acquiring': 102,\n",
              " 'acquisition': 103,\n",
              " 'acrida': 104,\n",
              " 'across': 105,\n",
              " 'act': 106,\n",
              " 'acted': 107,\n",
              " 'acting': 108,\n",
              " 'action': 109,\n",
              " 'actions': 110,\n",
              " 'activatable': 111,\n",
              " 'activate': 112,\n",
              " 'activated': 113,\n",
              " 'active': 114,\n",
              " 'activist': 115,\n",
              " 'activists': 116,\n",
              " 'activities': 117,\n",
              " 'activity': 118,\n",
              " 'actor': 119,\n",
              " 'acts': 120,\n",
              " 'actual': 121,\n",
              " 'actually': 122,\n",
              " 'acute': 123,\n",
              " 'acyclic': 124,\n",
              " 'ad': 125,\n",
              " 'adam': 126,\n",
              " 'adapt': 127,\n",
              " 'adaptaion': 128,\n",
              " 'add': 129,\n",
              " 'added': 130,\n",
              " 'addition': 131,\n",
              " 'additional': 132,\n",
              " 'address': 133,\n",
              " 'addressed': 134,\n",
              " 'addresses': 135,\n",
              " 'addressing': 136,\n",
              " 'adds': 137,\n",
              " 'adept': 138,\n",
              " 'adequate': 139,\n",
              " 'adequately': 140,\n",
              " 'adhatoda': 141,\n",
              " 'adhered': 142,\n",
              " 'adhering': 143,\n",
              " 'adhishthana': 144,\n",
              " 'adhvaryugan': 145,\n",
              " 'adjoining': 146,\n",
              " 'adjourned': 147,\n",
              " 'adjournment': 148,\n",
              " 'adjudicate': 149,\n",
              " 'adjudication': 150,\n",
              " 'adjust': 151,\n",
              " 'adjustment': 152,\n",
              " 'administering': 153,\n",
              " 'administration': 154,\n",
              " 'administrative': 155,\n",
              " 'administrator': 156,\n",
              " 'administrators': 157,\n",
              " 'admirer': 158,\n",
              " 'admission': 159,\n",
              " 'admit': 160,\n",
              " 'admits': 161,\n",
              " 'admitted': 162,\n",
              " 'admittedly': 163,\n",
              " 'admitting': 164,\n",
              " 'admonish': 165,\n",
              " 'adopt': 166,\n",
              " 'adopted': 167,\n",
              " 'adoption': 168,\n",
              " 'adult': 169,\n",
              " 'adults': 170,\n",
              " 'advance': 171,\n",
              " 'advanced': 172,\n",
              " 'advancing': 173,\n",
              " 'advani': 174,\n",
              " 'advantage': 175,\n",
              " 'advantageous': 176,\n",
              " 'adventure': 177,\n",
              " 'adverse': 178,\n",
              " 'adversity': 179,\n",
              " 'advice': 180,\n",
              " 'advisable': 181,\n",
              " 'advised': 182,\n",
              " 'adviser': 183,\n",
              " 'advisory': 184,\n",
              " 'advocate': 185,\n",
              " 'advocated': 186,\n",
              " 'advocates': 187,\n",
              " 'adwords': 188,\n",
              " 'aegis': 189,\n",
              " 'aerodromes': 190,\n",
              " 'aerosols': 191,\n",
              " 'aerospace': 192,\n",
              " 'aesthesis': 193,\n",
              " 'aesthetic': 194,\n",
              " 'aesthetical': 195,\n",
              " 'affair': 196,\n",
              " 'affairs': 197,\n",
              " 'affect': 198,\n",
              " 'affected': 199,\n",
              " 'affecting': 200,\n",
              " 'affection': 201,\n",
              " 'affects': 202,\n",
              " 'affiliate': 203,\n",
              " 'affiliated': 204,\n",
              " 'affiliations': 205,\n",
              " 'affixed': 206,\n",
              " 'affixing': 207,\n",
              " 'afflict': 208,\n",
              " 'afflicted': 209,\n",
              " 'affliction': 210,\n",
              " 'affluent': 211,\n",
              " 'afford': 212,\n",
              " 'affordability': 213,\n",
              " 'affordable': 214,\n",
              " 'afghan': 215,\n",
              " 'afghanistan': 216,\n",
              " 'afghans': 217,\n",
              " 'afore': 218,\n",
              " 'aforesaid': 219,\n",
              " 'afraid': 220,\n",
              " 'africa': 221,\n",
              " 'africans': 222,\n",
              " 'after': 223,\n",
              " 'aftermath': 224,\n",
              " 'afternoon': 225,\n",
              " 'afterthought': 226,\n",
              " 'afterward': 227,\n",
              " 'afterwards': 228,\n",
              " 'aga': 229,\n",
              " 'again': 230,\n",
              " 'against': 231,\n",
              " 'age': 232,\n",
              " 'aged': 233,\n",
              " 'ageing': 234,\n",
              " 'agencies': 235,\n",
              " 'agency': 236,\n",
              " 'agenda': 237,\n",
              " 'agent': 238,\n",
              " 'agents': 239,\n",
              " 'ages': 240,\n",
              " 'ageâ\\x80the': 241,\n",
              " 'aggressive': 242,\n",
              " 'aggressively': 243,\n",
              " 'aging': 244,\n",
              " 'agitated': 245,\n",
              " 'agitation': 246,\n",
              " 'agitationists': 247,\n",
              " 'agni': 248,\n",
              " 'ago': 249,\n",
              " 'agony': 250,\n",
              " 'agra': 251,\n",
              " 'agree': 252,\n",
              " 'agreeable': 253,\n",
              " 'agreed': 254,\n",
              " 'agreement': 255,\n",
              " 'agreements': 256,\n",
              " 'agricultural': 257,\n",
              " 'agriculturally': 258,\n",
              " 'agriculture': 259,\n",
              " 'agro': 260,\n",
              " 'agroforestry': 261,\n",
              " 'ağdan': 262,\n",
              " 'ahadpane': 263,\n",
              " 'ahirs': 264,\n",
              " 'ahmed': 265,\n",
              " 'aid': 266,\n",
              " 'aided': 267,\n",
              " 'ails': 268,\n",
              " 'aim': 269,\n",
              " 'aimed': 270,\n",
              " 'air': 271,\n",
              " 'airborne': 272,\n",
              " 'aircraft': 273,\n",
              " 'airline': 274,\n",
              " 'airport': 275,\n",
              " 'airtight': 276,\n",
              " 'aisles': 277,\n",
              " 'ait': 278,\n",
              " 'aituc': 279,\n",
              " 'ajodhya': 280,\n",
              " 'akbar': 281,\n",
              " 'akin': 282,\n",
              " 'akp': 283,\n",
              " 'aksharmukh': 284,\n",
              " 'akshoya': 285,\n",
              " 'al': 286,\n",
              " 'alaknanda': 287,\n",
              " 'alam': 288,\n",
              " 'alan': 289,\n",
              " 'alankara': 290,\n",
              " 'alarm': 291,\n",
              " 'alarming': 292,\n",
              " 'alchemy': 293,\n",
              " 'alco': 294,\n",
              " 'alcohol': 295,\n",
              " 'alert': 296,\n",
              " 'aletta': 297,\n",
              " 'alexandrine': 298,\n",
              " 'algae': 299,\n",
              " 'algebraic': 300,\n",
              " 'algeria': 301,\n",
              " 'alghbgh': 302,\n",
              " 'algorithm': 303,\n",
              " 'algorithms': 304,\n",
              " 'ali': 305,\n",
              " 'alienate': 306,\n",
              " 'alienation': 307,\n",
              " 'alif': 308,\n",
              " 'alike': 309,\n",
              " 'alive': 310,\n",
              " 'ali“': 311,\n",
              " 'all': 312,\n",
              " 'allah': 313,\n",
              " 'allahabad': 314,\n",
              " 'allah’s': 315,\n",
              " 'allegations': 316,\n",
              " 'alleged': 317,\n",
              " 'allegiance': 318,\n",
              " 'allergic': 319,\n",
              " 'alleviation': 320,\n",
              " 'allied': 321,\n",
              " 'allocate': 322,\n",
              " 'allocated': 323,\n",
              " 'allocation': 324,\n",
              " 'allotropic': 325,\n",
              " 'allotted': 326,\n",
              " 'allow': 327,\n",
              " 'allowable': 328,\n",
              " 'allowance': 329,\n",
              " 'allowed': 330,\n",
              " 'allowing': 331,\n",
              " 'alltv': 332,\n",
              " 'alluded': 333,\n",
              " 'almaty': 334,\n",
              " 'almighty': 335,\n",
              " 'almirahs': 336,\n",
              " 'almost': 337,\n",
              " 'alms': 338,\n",
              " 'alois': 339,\n",
              " 'alone': 340,\n",
              " 'along': 341,\n",
              " 'alongside': 342,\n",
              " 'alps': 343,\n",
              " 'already': 344,\n",
              " 'also': 345,\n",
              " 'alter': 346,\n",
              " 'alteration': 347,\n",
              " 'altered': 348,\n",
              " 'alternate': 349,\n",
              " 'alternative': 350,\n",
              " 'alternatives': 351,\n",
              " 'although': 352,\n",
              " 'altitude': 353,\n",
              " 'alumni': 354,\n",
              " 'alveolar': 355,\n",
              " 'always': 356,\n",
              " 'am': 357,\n",
              " 'amah': 358,\n",
              " 'amalakas': 359,\n",
              " 'amartya': 360,\n",
              " 'amazement': 361,\n",
              " 'ambit': 362,\n",
              " 'ambitious': 363,\n",
              " 'ambush': 364,\n",
              " 'amended': 365,\n",
              " 'amenities': 366,\n",
              " 'america': 367,\n",
              " 'american': 368,\n",
              " 'americans': 369,\n",
              " 'americanused': 370,\n",
              " 'amino': 371,\n",
              " 'amitabh': 372,\n",
              " 'amitabha': 373,\n",
              " 'amma': 374,\n",
              " 'ammal': 375,\n",
              " 'amnesty': 376,\n",
              " 'amniotic': 377,\n",
              " 'among': 378,\n",
              " 'amongst': 379,\n",
              " 'amortization': 380,\n",
              " 'amos': 381,\n",
              " 'amount': 382,\n",
              " 'amounted': 383,\n",
              " 'amounting': 384,\n",
              " 'amplifies': 385,\n",
              " 'amravati': 386,\n",
              " 'amritsar': 387,\n",
              " 'amtur': 388,\n",
              " 'amylum': 389,\n",
              " 'an': 390,\n",
              " 'ana': 391,\n",
              " 'anachronistic': 392,\n",
              " 'analgesics': 393,\n",
              " 'analogy': 394,\n",
              " 'analysis': 395,\n",
              " 'analysts': 396,\n",
              " 'anandamoyi': 397,\n",
              " 'ananta': 398,\n",
              " 'anatomic': 399,\n",
              " 'ancestors': 400,\n",
              " 'ancient': 401,\n",
              " 'and': 402,\n",
              " 'andaman': 403,\n",
              " 'andhra': 404,\n",
              " 'andorran': 405,\n",
              " 'anemia': 406,\n",
              " 'anesthesia': 407,\n",
              " 'angel': 408,\n",
              " 'angeles': 409,\n",
              " 'angels': 410,\n",
              " 'angle': 411,\n",
              " 'anglicists': 412,\n",
              " 'anglo': 413,\n",
              " 'angloindian': 414,\n",
              " 'angry': 415,\n",
              " 'anguish': 416,\n",
              " 'anil': 417,\n",
              " 'animal': 418,\n",
              " 'animals': 419,\n",
              " 'animation': 420,\n",
              " 'anjar': 421,\n",
              " 'anjuta': 422,\n",
              " 'ankle': 423,\n",
              " 'annada': 424,\n",
              " 'annapurna': 425,\n",
              " 'anniversaries': 426,\n",
              " 'anniversary': 427,\n",
              " 'announced': 428,\n",
              " 'announcer': 429,\n",
              " 'annoyance': 430,\n",
              " 'annual': 431,\n",
              " 'annuities': 432,\n",
              " 'annulled': 433,\n",
              " 'another': 434,\n",
              " 'ansari': 435,\n",
              " 'ansicht': 436,\n",
              " 'answer': 437,\n",
              " 'answered': 438,\n",
              " 'answers': 439,\n",
              " 'ant': 440,\n",
              " 'antananarivo': 441,\n",
              " 'antarctic': 442,\n",
              " 'antarctica': 443,\n",
              " 'antariya': 444,\n",
              " 'antennae': 445,\n",
              " 'anthem': 446,\n",
              " 'anthony': 447,\n",
              " 'anthropologist': 448,\n",
              " 'anthropology': 449,\n",
              " 'anti': 450,\n",
              " 'antialiasing': 451,\n",
              " 'antiderivative': 452,\n",
              " 'antidote': 453,\n",
              " 'antipathy': 454,\n",
              " 'antipernicious': 455,\n",
              " 'antonym': 456,\n",
              " 'anu': 457,\n",
              " 'anuran': 458,\n",
              " 'anwar': 459,\n",
              " 'anxious': 460,\n",
              " 'any': 461,\n",
              " 'anybody': 462,\n",
              " 'anyhow': 463,\n",
              " 'anyone': 464,\n",
              " 'anything': 465,\n",
              " 'anyway': 466,\n",
              " 'aol': 467,\n",
              " 'aotus': 468,\n",
              " 'apace': 469,\n",
              " 'apart': 470,\n",
              " 'apartheid': 471,\n",
              " 'apathy': 472,\n",
              " 'apes': 473,\n",
              " 'apex': 474,\n",
              " 'api': 475,\n",
              " 'apiculture': 476,\n",
              " 'aponline': 477,\n",
              " 'apostle': 478,\n",
              " 'apostles': 479,\n",
              " 'apostle’s': 480,\n",
              " 'app': 481,\n",
              " 'appar': 482,\n",
              " 'apparently': 483,\n",
              " 'appeal': 484,\n",
              " 'appeals': 485,\n",
              " 'appear': 486,\n",
              " 'appearance': 487,\n",
              " 'appeared': 488,\n",
              " 'appears': 489,\n",
              " 'appease': 490,\n",
              " 'appellant': 491,\n",
              " 'appellate': 492,\n",
              " 'append': 493,\n",
              " 'appending': 494,\n",
              " 'appendix': 495,\n",
              " 'appetite': 496,\n",
              " 'applaudable': 497,\n",
              " 'applauded': 498,\n",
              " 'applause': 499,\n",
              " 'apple': 500,\n",
              " 'applet': 501,\n",
              " 'applicable': 502,\n",
              " 'applicantthe': 503,\n",
              " 'application': 504,\n",
              " 'applications': 505,\n",
              " 'applied': 506,\n",
              " 'applies': 507,\n",
              " 'apply': 508,\n",
              " 'applying': 509,\n",
              " 'appoinment': 510,\n",
              " 'appoint': 511,\n",
              " 'appointed': 512,\n",
              " 'appointment': 513,\n",
              " 'appraisals': 514,\n",
              " 'appreciate': 515,\n",
              " 'appreciated': 516,\n",
              " 'appreciating': 517,\n",
              " 'appreciation': 518,\n",
              " 'apprehended': 519,\n",
              " 'approach': 520,\n",
              " 'approached': 521,\n",
              " 'approaches': 522,\n",
              " 'approaching': 523,\n",
              " 'appropriated': 524,\n",
              " 'approval': 525,\n",
              " 'approved': 526,\n",
              " 'approximate': 527,\n",
              " 'approximately': 528,\n",
              " 'approximation': 529,\n",
              " 'apps': 530,\n",
              " 'april': 531,\n",
              " 'apt': 532,\n",
              " 'aquatic': 533,\n",
              " 'arab': 534,\n",
              " 'arabic': 535,\n",
              " 'arbitral': 536,\n",
              " 'arbitrary': 537,\n",
              " 'arbitration': 538,\n",
              " 'arbitrator': 539,\n",
              " 'arbitrators': 540,\n",
              " 'archaeological': 541,\n",
              " 'archaeology': 542,\n",
              " 'arches': 543,\n",
              " 'archimedes': 544,\n",
              " 'architecture': 545,\n",
              " 'are': 546,\n",
              " 'area': 547,\n",
              " 'areas': 548,\n",
              " 'areopagitica': 549,\n",
              " 'arg': 550,\n",
              " 'argentina': 551,\n",
              " 'argue': 552,\n",
              " 'argued': 553,\n",
              " 'argues': 554,\n",
              " 'argument': 555,\n",
              " 'argyle': 556,\n",
              " 'arim': 557,\n",
              " 'arise': 558,\n",
              " 'aristocratic': 559,\n",
              " 'arithmetic': 560,\n",
              " 'arithmetical': 561,\n",
              " 'arkansas': 562,\n",
              " 'armed': 563,\n",
              " 'armenian': 564,\n",
              " 'armies': 565,\n",
              " 'armlet': 566,\n",
              " 'arms': 567,\n",
              " 'armscii': 568,\n",
              " 'army': 569,\n",
              " 'aromatic': 570,\n",
              " 'aromaticum': 571,\n",
              " 'around': 572,\n",
              " 'aroused': 573,\n",
              " 'arranged': 574,\n",
              " 'arrangement': 575,\n",
              " 'arrangements': 576,\n",
              " 'arranta': 577,\n",
              " 'arraying': 578,\n",
              " 'arrears': 579,\n",
              " 'arrest': 580,\n",
              " 'arrested': 581,\n",
              " 'arrests': 582,\n",
              " 'arrival': 583,\n",
              " 'arrivals': 584,\n",
              " 'arrive': 585,\n",
              " 'arrived': 586,\n",
              " 'arriving': 587,\n",
              " 'arrogant': 588,\n",
              " 'arrow': 589,\n",
              " 'arrows': 590,\n",
              " 'arrr': 591,\n",
              " 'arsenic': 592,\n",
              " 'art': 593,\n",
              " 'arteries': 594,\n",
              " 'arthropod': 595,\n",
              " 'arthropods': 596,\n",
              " 'article': 597,\n",
              " 'articles': 598,\n",
              " 'articulate': 599,\n",
              " 'artisans': 600,\n",
              " 'artist': 601,\n",
              " 'artists': 602,\n",
              " 'arts': 603,\n",
              " 'arun': 604,\n",
              " 'aryan': 605,\n",
              " 'as': 606,\n",
              " 'asa': 607,\n",
              " 'asar': 608,\n",
              " 'ascendency': 609,\n",
              " 'ascending': 610,\n",
              " 'ascent': 611,\n",
              " 'ascetic': 612,\n",
              " 'ascii': 613,\n",
              " 'ascribe': 614,\n",
              " 'ascribed': 615,\n",
              " 'ascribes': 616,\n",
              " 'ashamedp': 617,\n",
              " 'ashes': 618,\n",
              " 'ashrushti': 619,\n",
              " 'ashutosh': 620,\n",
              " 'asia': 621,\n",
              " 'asian': 622,\n",
              " 'asians': 623,\n",
              " 'asiatic': 624,\n",
              " 'aside': 625,\n",
              " 'ask': 626,\n",
              " 'asked': 627,\n",
              " 'asking': 628,\n",
              " 'asom': 629,\n",
              " 'asparagus': 630,\n",
              " 'aspect': 631,\n",
              " 'aspects': 632,\n",
              " 'aspergery': 633,\n",
              " 'aspiration': 634,\n",
              " 'aspirations': 635,\n",
              " 'aspire': 636,\n",
              " 'ass': 637,\n",
              " 'assam': 638,\n",
              " 'assembled': 639,\n",
              " 'assemblies': 640,\n",
              " 'assembly': 641,\n",
              " 'assent': 642,\n",
              " 'assert': 643,\n",
              " 'asserted': 644,\n",
              " 'assertion': 645,\n",
              " 'assess': 646,\n",
              " 'assessed': 647,\n",
              " 'assessee': 648,\n",
              " 'assesses': 649,\n",
              " 'assessing': 650,\n",
              " 'assessment': 651,\n",
              " 'asset': 652,\n",
              " 'assets': 653,\n",
              " 'asshole': 654,\n",
              " 'assigned': 655,\n",
              " 'assist': 656,\n",
              " 'assistance': 657,\n",
              " 'assistant': 658,\n",
              " 'assistants': 659,\n",
              " 'assisting': 660,\n",
              " 'associate': 661,\n",
              " 'associated': 662,\n",
              " 'associates': 663,\n",
              " 'association': 664,\n",
              " 'associations': 665,\n",
              " 'assume': 666,\n",
              " 'assumed': 667,\n",
              " 'assured': 668,\n",
              " 'assuredly': 669,\n",
              " 'astama': 670,\n",
              " 'asthenia': 671,\n",
              " 'astra': 672,\n",
              " 'astray': 673,\n",
              " 'astute': 674,\n",
              " 'asunder': 675,\n",
              " 'asurl': 676,\n",
              " 'asutosh': 677,\n",
              " 'aswaghosa': 678,\n",
              " 'asymptomatic': 679,\n",
              " 'asymptotically': 680,\n",
              " 'as…': 681,\n",
              " 'at': 682,\n",
              " 'ataxia': 683,\n",
              " 'ate': 684,\n",
              " 'athene': 685,\n",
              " 'atikokan': 686,\n",
              " 'atleast': 687,\n",
              " 'atm': 688,\n",
              " 'atmosphere': 689,\n",
              " 'atmospheric': 690,\n",
              " 'atoms': 691,\n",
              " 'atone': 692,\n",
              " 'atones': 693,\n",
              " 'attach': 694,\n",
              " 'attached': 695,\n",
              " 'attaches': 696,\n",
              " 'attachment': 697,\n",
              " 'attack': 698,\n",
              " 'attacked': 699,\n",
              " 'attacks': 700,\n",
              " 'attain': 701,\n",
              " 'attained': 702,\n",
              " 'attaining': 703,\n",
              " 'attainments': 704,\n",
              " 'attains': 705,\n",
              " 'attempt': 706,\n",
              " 'attempted': 707,\n",
              " 'attempts': 708,\n",
              " 'attend': 709,\n",
              " 'attendance': 710,\n",
              " 'attendants': 711,\n",
              " 'attended': 712,\n",
              " 'attendees': 713,\n",
              " 'attention': 714,\n",
              " 'attitude': 715,\n",
              " 'attitudes': 716,\n",
              " 'attorney': 717,\n",
              " 'attract': 718,\n",
              " 'attracted': 719,\n",
              " 'attractions': 720,\n",
              " 'attributable': 721,\n",
              " 'attribute': 722,\n",
              " 'attuc': 723,\n",
              " 'atualizar': 724,\n",
              " 'atulya': 725,\n",
              " 'auction': 726,\n",
              " 'audio': 727,\n",
              " 'audiogram': 728,\n",
              " 'audit': 729,\n",
              " 'audrey': 730,\n",
              " 'aught': 731,\n",
              " 'augment': 732,\n",
              " 'augmenting': 733,\n",
              " 'august': 734,\n",
              " 'augustin': 735,\n",
              " 'aun': 736,\n",
              " 'aurorae': 737,\n",
              " 'auroville': 738,\n",
              " 'auspicious': 739,\n",
              " 'australia': 740,\n",
              " 'austria': 741,\n",
              " 'authentication': 742,\n",
              " 'author': 743,\n",
              " 'authorisation': 744,\n",
              " 'authorisations': 745,\n",
              " 'authorised': 746,\n",
              " 'authoritarianism': 747,\n",
              " 'authorities': 748,\n",
              " 'authority': 749,\n",
              " 'authors': 750,\n",
              " 'autism': 751,\n",
              " 'auto': 752,\n",
              " 'autodiscover': 753,\n",
              " 'automatic': 754,\n",
              " 'automatically': 755,\n",
              " 'automobile': 756,\n",
              " 'automobiles': 757,\n",
              " 'automount': 758,\n",
              " 'autonomous': 759,\n",
              " 'autonomy': 760,\n",
              " 'autopolyploidy': 761,\n",
              " 'autoprobed': 762,\n",
              " 'avail': 763,\n",
              " 'availability': 764,\n",
              " 'available': 765,\n",
              " 'availed': 766,\n",
              " 'avatar': 767,\n",
              " 'average': 768,\n",
              " 'averters': 769,\n",
              " 'aviation': 770,\n",
              " 'avner': 771,\n",
              " 'avoid': 772,\n",
              " 'avoidance': 773,\n",
              " 'avoided': 774,\n",
              " 'awadh': 775,\n",
              " 'awaited': 776,\n",
              " 'awaits': 777,\n",
              " 'awake': 778,\n",
              " 'award': 779,\n",
              " 'awarded': 780,\n",
              " 'awards': 781,\n",
              " 'aware': 782,\n",
              " 'awareness': 783,\n",
              " 'away': 784,\n",
              " 'awful': 785,\n",
              " 'awlaki': 786,\n",
              " 'axes': 787,\n",
              " 'axis': 788,\n",
              " 'ayat': 789,\n",
              " 'aye': 790,\n",
              " 'ayesha': 791,\n",
              " 'ayodhya': 792,\n",
              " 'ayora': 793,\n",
              " 'ayrıldı': 794,\n",
              " 'ayurveda': 795,\n",
              " 'azar': 796,\n",
              " 'aziz': 797,\n",
              " 'aztec': 798,\n",
              " 'à': 799,\n",
              " 'b': 800,\n",
              " 'ba': 801,\n",
              " 'baad': 802,\n",
              " 'baat': 803,\n",
              " 'baaten': 804,\n",
              " 'baazi': 805,\n",
              " 'baba': 806,\n",
              " 'babariawad': 807,\n",
              " 'babu': 808,\n",
              " 'baby': 809,\n",
              " 'babylonia': 810,\n",
              " 'bacchan': 811,\n",
              " 'bachchan': 812,\n",
              " 'bachelor': 813,\n",
              " 'bachendri': 814,\n",
              " 'bachhan': 815,\n",
              " 'back': 816,\n",
              " 'background': 817,\n",
              " 'backlogsomewhat': 818,\n",
              " 'backoff': 819,\n",
              " 'backup': 820,\n",
              " 'backward': 821,\n",
              " 'bacteria': 822,\n",
              " 'bad': 823,\n",
              " 'badh': 824,\n",
              " 'badly': 825,\n",
              " 'bag': 826,\n",
              " 'bagh': 827,\n",
              " 'baghban': 828,\n",
              " 'baghdad': 829,\n",
              " 'bahadur': 830,\n",
              " 'baham': 831,\n",
              " 'bahamani': 832,\n",
              " 'bahinse“”': 833,\n",
              " 'bahraich': 834,\n",
              " 'bail': 835,\n",
              " 'bailiff': 836,\n",
              " 'bailment': 837,\n",
              " 'bajirao': 838,\n",
              " 'bal': 839,\n",
              " 'balance': 840,\n",
              " 'balanced': 841,\n",
              " 'balancing': 842,\n",
              " 'balappa': 843,\n",
              " 'balaram': 844,\n",
              " 'balarama': 845,\n",
              " 'bald': 846,\n",
              " 'balkh': 847,\n",
              " 'ball': 848,\n",
              " 'bamboo': 849,\n",
              " 'banana': 850,\n",
              " 'band': 851,\n",
              " 'bande': 852,\n",
              " 'banded': 853,\n",
              " 'bandha': 854,\n",
              " 'bandimet': 855,\n",
              " 'banerjee': 856,\n",
              " 'bangadarsan': 857,\n",
              " 'bangalore': 858,\n",
              " 'bangaluru': 859,\n",
              " 'bangladesh': 860,\n",
              " 'banhi': 861,\n",
              " 'bank': 862,\n",
              " 'bankim': 863,\n",
              " 'bankimchandra': 864,\n",
              " 'banking': 865,\n",
              " 'banknotes': 866,\n",
              " 'bankruptcy': 867,\n",
              " 'banks': 868,\n",
              " 'banner': 869,\n",
              " 'bannister': 870,\n",
              " 'banquet': 871,\n",
              " 'banyan': 872,\n",
              " 'bapu': 873,\n",
              " 'bapusaheb': 874,\n",
              " 'bar': 875,\n",
              " 'bara': 876,\n",
              " 'barbarism': 877,\n",
              " 'barco': 878,\n",
              " 'bare': 879,\n",
              " 'barefoot': 880,\n",
              " 'barely': 881,\n",
              " 'barfi': 882,\n",
              " 'bargaining': 883,\n",
              " 'bargains': 884,\n",
              " 'barley': 885,\n",
              " 'barowari': 886,\n",
              " 'barratry': 887,\n",
              " 'barren': 888,\n",
              " 'barricade': 889,\n",
              " 'barristers': 890,\n",
              " 'bars': 891,\n",
              " 'basal': 892,\n",
              " 'base': 893,\n",
              " 'based': 894,\n",
              " 'bash': 895,\n",
              " 'basic': 896,\n",
              " 'basically': 897,\n",
              " 'basin': 898,\n",
              " 'basis': 899,\n",
              " 'basket': 900,\n",
              " 'başka': 901,\n",
              " 'bath': 902,\n",
              " 'bathroom': 903,\n",
              " 'battalion': 904,\n",
              " 'battalions': 905,\n",
              " 'battering': 906,\n",
              " 'battery': 907,\n",
              " 'battle': 908,\n",
              " 'battlefield': 909,\n",
              " 'battles': 910,\n",
              " 'battling': 911,\n",
              " 'bay': 912,\n",
              " 'bc': 913,\n",
              " 'be': 914,\n",
              " 'beacon': 915,\n",
              " 'bear': 916,\n",
              " 'bearer': 917,\n",
              " 'beareth': 918,\n",
              " 'bearing': 919,\n",
              " 'beasts': 920,\n",
              " 'beaten': 921,\n",
              " 'beating': 922,\n",
              " 'beats': 923,\n",
              " 'beautiful': 924,\n",
              " 'beautifully': 925,\n",
              " 'beauty': 926,\n",
              " 'became': 927,\n",
              " 'because': 928,\n",
              " 'become': 929,\n",
              " 'becomes': 930,\n",
              " 'becometh': 931,\n",
              " 'becoming': 932,\n",
              " 'bed': 933,\n",
              " 'bedsheet': 934,\n",
              " 'been': 935,\n",
              " 'befallen': 936,\n",
              " 'befalls': 937,\n",
              " 'befell': 938,\n",
              " 'before': 939,\n",
              " 'began': 940,\n",
              " 'begets': 941,\n",
              " 'beggar': 942,\n",
              " 'begging': 943,\n",
              " 'begin': 944,\n",
              " 'beginner': 945,\n",
              " 'beginning': 946,\n",
              " 'beginnings': 947,\n",
              " 'begins': 948,\n",
              " 'begotten': 949,\n",
              " 'behalf': 950,\n",
              " 'behave': 951,\n",
              " 'behaved': 952,\n",
              " 'behavior': 953,\n",
              " 'behaviour': 954,\n",
              " 'beheaded': 955,\n",
              " 'beheld': 956,\n",
              " 'behind': 957,\n",
              " 'behold': 958,\n",
              " 'being': 959,\n",
              " 'beings': 960,\n",
              " 'bejoy': 961,\n",
              " 'bekaner': 962,\n",
              " 'belarus': 963,\n",
              " 'belarusian': 964,\n",
              " 'belgachia': 965,\n",
              " 'belgaum': 966,\n",
              " 'belgian': 967,\n",
              " 'belie': 968,\n",
              " 'belied': 969,\n",
              " 'belief': 970,\n",
              " 'beliefs': 971,\n",
              " 'believe': 972,\n",
              " 'believed': 973,\n",
              " 'believer': 974,\n",
              " 'believers': 975,\n",
              " 'believes': 976,\n",
              " 'believing': 977,\n",
              " 'bella': 978,\n",
              " 'belong': 979,\n",
              " 'belonging': 980,\n",
              " 'belongings': 981,\n",
              " 'belongs': 982,\n",
              " 'belonolaimidae': 983,\n",
              " 'belorussian': 984,\n",
              " 'beloved': 985,\n",
              " 'below': 986,\n",
              " 'ben': 987,\n",
              " 'beneath': 988,\n",
              " 'beneficent': 989,\n",
              " 'beneficial': 990,\n",
              " 'benefit': 991,\n",
              " 'benefits': 992,\n",
              " 'benefitted': 993,\n",
              " 'benevolence': 994,\n",
              " 'bengal': 995,\n",
              " 'bengalensis': 996,\n",
              " 'bengali': 997,\n",
              " 'bengalis': 998,\n",
              " 'beoti': 999,\n",
              " 'berkshire': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "input_token_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "R-BCNkr4ZuYs"
      },
      "outputs": [],
      "source": [
        "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUbOWMaoZve4",
        "outputId": "5d855ea8-20cc-4192-827b-10c3f357e0ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'a',\n",
              " 2: 'aa',\n",
              " 3: 'aakashdeep',\n",
              " 4: 'aampapad',\n",
              " 5: 'aaron',\n",
              " 6: 'aastuny',\n",
              " 7: 'abandon',\n",
              " 8: 'abase',\n",
              " 9: 'abasements',\n",
              " 10: 'abated',\n",
              " 11: 'abating',\n",
              " 12: 'abdel',\n",
              " 13: 'abdul',\n",
              " 14: 'abhi',\n",
              " 15: 'abhinav',\n",
              " 16: 'abide',\n",
              " 17: 'abiding',\n",
              " 18: 'abidjan',\n",
              " 19: 'ability',\n",
              " 20: 'abiword',\n",
              " 21: 'able',\n",
              " 22: 'abnormal',\n",
              " 23: 'abnormally',\n",
              " 24: 'abode',\n",
              " 25: 'abomination',\n",
              " 26: 'about',\n",
              " 27: 'above',\n",
              " 28: 'abraham',\n",
              " 29: 'abroad',\n",
              " 30: 'abruptly',\n",
              " 31: 'abscess',\n",
              " 32: 'absence',\n",
              " 33: 'absent',\n",
              " 34: 'absents',\n",
              " 35: 'absolute',\n",
              " 36: 'absolutely',\n",
              " 37: 'absolution',\n",
              " 38: 'absorb',\n",
              " 39: 'absorbed',\n",
              " 40: 'abstract',\n",
              " 41: 'absurd',\n",
              " 42: 'abtar',\n",
              " 43: 'abu',\n",
              " 44: 'abundant',\n",
              " 45: 'abuse',\n",
              " 46: 'academic',\n",
              " 47: 'academics',\n",
              " 48: 'academy',\n",
              " 49: 'acceded',\n",
              " 50: 'accentuation',\n",
              " 51: 'accept',\n",
              " 52: 'acceptable',\n",
              " 53: 'acceptance',\n",
              " 54: 'accepted',\n",
              " 55: 'accepting',\n",
              " 56: 'accepts',\n",
              " 57: 'access',\n",
              " 58: 'accessed',\n",
              " 59: 'accessibility',\n",
              " 60: 'accessing',\n",
              " 61: 'accident',\n",
              " 62: 'accidents',\n",
              " 63: 'accompanied',\n",
              " 64: 'accompaniment',\n",
              " 65: 'accompany',\n",
              " 66: 'accomplish',\n",
              " 67: 'accomplishment',\n",
              " 68: 'accord',\n",
              " 69: 'accordance',\n",
              " 70: 'accorded',\n",
              " 71: 'according',\n",
              " 72: 'accordingly',\n",
              " 73: 'account',\n",
              " 74: 'accountability',\n",
              " 75: 'accountant',\n",
              " 76: 'accounting',\n",
              " 77: 'accounts',\n",
              " 78: 'accredited',\n",
              " 79: 'accrue',\n",
              " 80: 'accumulated',\n",
              " 81: 'accurate',\n",
              " 82: 'accused',\n",
              " 83: 'ace',\n",
              " 84: 'aceh',\n",
              " 85: 'acharya',\n",
              " 86: 'achieve',\n",
              " 87: 'achieved',\n",
              " 88: 'achievement',\n",
              " 89: 'achievements',\n",
              " 90: 'achievers',\n",
              " 91: 'acid',\n",
              " 92: 'acidic',\n",
              " 93: 'acids',\n",
              " 94: 'acids葉ransfer',\n",
              " 95: 'acknowledged',\n",
              " 96: 'acknowledges',\n",
              " 97: 'aclean',\n",
              " 98: 'acquainted',\n",
              " 99: 'acquiesced',\n",
              " 100: 'acquire',\n",
              " 101: 'acquired',\n",
              " 102: 'acquiring',\n",
              " 103: 'acquisition',\n",
              " 104: 'acrida',\n",
              " 105: 'across',\n",
              " 106: 'act',\n",
              " 107: 'acted',\n",
              " 108: 'acting',\n",
              " 109: 'action',\n",
              " 110: 'actions',\n",
              " 111: 'activatable',\n",
              " 112: 'activate',\n",
              " 113: 'activated',\n",
              " 114: 'active',\n",
              " 115: 'activist',\n",
              " 116: 'activists',\n",
              " 117: 'activities',\n",
              " 118: 'activity',\n",
              " 119: 'actor',\n",
              " 120: 'acts',\n",
              " 121: 'actual',\n",
              " 122: 'actually',\n",
              " 123: 'acute',\n",
              " 124: 'acyclic',\n",
              " 125: 'ad',\n",
              " 126: 'adam',\n",
              " 127: 'adapt',\n",
              " 128: 'adaptaion',\n",
              " 129: 'add',\n",
              " 130: 'added',\n",
              " 131: 'addition',\n",
              " 132: 'additional',\n",
              " 133: 'address',\n",
              " 134: 'addressed',\n",
              " 135: 'addresses',\n",
              " 136: 'addressing',\n",
              " 137: 'adds',\n",
              " 138: 'adept',\n",
              " 139: 'adequate',\n",
              " 140: 'adequately',\n",
              " 141: 'adhatoda',\n",
              " 142: 'adhered',\n",
              " 143: 'adhering',\n",
              " 144: 'adhishthana',\n",
              " 145: 'adhvaryugan',\n",
              " 146: 'adjoining',\n",
              " 147: 'adjourned',\n",
              " 148: 'adjournment',\n",
              " 149: 'adjudicate',\n",
              " 150: 'adjudication',\n",
              " 151: 'adjust',\n",
              " 152: 'adjustment',\n",
              " 153: 'administering',\n",
              " 154: 'administration',\n",
              " 155: 'administrative',\n",
              " 156: 'administrator',\n",
              " 157: 'administrators',\n",
              " 158: 'admirer',\n",
              " 159: 'admission',\n",
              " 160: 'admit',\n",
              " 161: 'admits',\n",
              " 162: 'admitted',\n",
              " 163: 'admittedly',\n",
              " 164: 'admitting',\n",
              " 165: 'admonish',\n",
              " 166: 'adopt',\n",
              " 167: 'adopted',\n",
              " 168: 'adoption',\n",
              " 169: 'adult',\n",
              " 170: 'adults',\n",
              " 171: 'advance',\n",
              " 172: 'advanced',\n",
              " 173: 'advancing',\n",
              " 174: 'advani',\n",
              " 175: 'advantage',\n",
              " 176: 'advantageous',\n",
              " 177: 'adventure',\n",
              " 178: 'adverse',\n",
              " 179: 'adversity',\n",
              " 180: 'advice',\n",
              " 181: 'advisable',\n",
              " 182: 'advised',\n",
              " 183: 'adviser',\n",
              " 184: 'advisory',\n",
              " 185: 'advocate',\n",
              " 186: 'advocated',\n",
              " 187: 'advocates',\n",
              " 188: 'adwords',\n",
              " 189: 'aegis',\n",
              " 190: 'aerodromes',\n",
              " 191: 'aerosols',\n",
              " 192: 'aerospace',\n",
              " 193: 'aesthesis',\n",
              " 194: 'aesthetic',\n",
              " 195: 'aesthetical',\n",
              " 196: 'affair',\n",
              " 197: 'affairs',\n",
              " 198: 'affect',\n",
              " 199: 'affected',\n",
              " 200: 'affecting',\n",
              " 201: 'affection',\n",
              " 202: 'affects',\n",
              " 203: 'affiliate',\n",
              " 204: 'affiliated',\n",
              " 205: 'affiliations',\n",
              " 206: 'affixed',\n",
              " 207: 'affixing',\n",
              " 208: 'afflict',\n",
              " 209: 'afflicted',\n",
              " 210: 'affliction',\n",
              " 211: 'affluent',\n",
              " 212: 'afford',\n",
              " 213: 'affordability',\n",
              " 214: 'affordable',\n",
              " 215: 'afghan',\n",
              " 216: 'afghanistan',\n",
              " 217: 'afghans',\n",
              " 218: 'afore',\n",
              " 219: 'aforesaid',\n",
              " 220: 'afraid',\n",
              " 221: 'africa',\n",
              " 222: 'africans',\n",
              " 223: 'after',\n",
              " 224: 'aftermath',\n",
              " 225: 'afternoon',\n",
              " 226: 'afterthought',\n",
              " 227: 'afterward',\n",
              " 228: 'afterwards',\n",
              " 229: 'aga',\n",
              " 230: 'again',\n",
              " 231: 'against',\n",
              " 232: 'age',\n",
              " 233: 'aged',\n",
              " 234: 'ageing',\n",
              " 235: 'agencies',\n",
              " 236: 'agency',\n",
              " 237: 'agenda',\n",
              " 238: 'agent',\n",
              " 239: 'agents',\n",
              " 240: 'ages',\n",
              " 241: 'ageâ\\x80the',\n",
              " 242: 'aggressive',\n",
              " 243: 'aggressively',\n",
              " 244: 'aging',\n",
              " 245: 'agitated',\n",
              " 246: 'agitation',\n",
              " 247: 'agitationists',\n",
              " 248: 'agni',\n",
              " 249: 'ago',\n",
              " 250: 'agony',\n",
              " 251: 'agra',\n",
              " 252: 'agree',\n",
              " 253: 'agreeable',\n",
              " 254: 'agreed',\n",
              " 255: 'agreement',\n",
              " 256: 'agreements',\n",
              " 257: 'agricultural',\n",
              " 258: 'agriculturally',\n",
              " 259: 'agriculture',\n",
              " 260: 'agro',\n",
              " 261: 'agroforestry',\n",
              " 262: 'ağdan',\n",
              " 263: 'ahadpane',\n",
              " 264: 'ahirs',\n",
              " 265: 'ahmed',\n",
              " 266: 'aid',\n",
              " 267: 'aided',\n",
              " 268: 'ails',\n",
              " 269: 'aim',\n",
              " 270: 'aimed',\n",
              " 271: 'air',\n",
              " 272: 'airborne',\n",
              " 273: 'aircraft',\n",
              " 274: 'airline',\n",
              " 275: 'airport',\n",
              " 276: 'airtight',\n",
              " 277: 'aisles',\n",
              " 278: 'ait',\n",
              " 279: 'aituc',\n",
              " 280: 'ajodhya',\n",
              " 281: 'akbar',\n",
              " 282: 'akin',\n",
              " 283: 'akp',\n",
              " 284: 'aksharmukh',\n",
              " 285: 'akshoya',\n",
              " 286: 'al',\n",
              " 287: 'alaknanda',\n",
              " 288: 'alam',\n",
              " 289: 'alan',\n",
              " 290: 'alankara',\n",
              " 291: 'alarm',\n",
              " 292: 'alarming',\n",
              " 293: 'alchemy',\n",
              " 294: 'alco',\n",
              " 295: 'alcohol',\n",
              " 296: 'alert',\n",
              " 297: 'aletta',\n",
              " 298: 'alexandrine',\n",
              " 299: 'algae',\n",
              " 300: 'algebraic',\n",
              " 301: 'algeria',\n",
              " 302: 'alghbgh',\n",
              " 303: 'algorithm',\n",
              " 304: 'algorithms',\n",
              " 305: 'ali',\n",
              " 306: 'alienate',\n",
              " 307: 'alienation',\n",
              " 308: 'alif',\n",
              " 309: 'alike',\n",
              " 310: 'alive',\n",
              " 311: 'ali“',\n",
              " 312: 'all',\n",
              " 313: 'allah',\n",
              " 314: 'allahabad',\n",
              " 315: 'allah’s',\n",
              " 316: 'allegations',\n",
              " 317: 'alleged',\n",
              " 318: 'allegiance',\n",
              " 319: 'allergic',\n",
              " 320: 'alleviation',\n",
              " 321: 'allied',\n",
              " 322: 'allocate',\n",
              " 323: 'allocated',\n",
              " 324: 'allocation',\n",
              " 325: 'allotropic',\n",
              " 326: 'allotted',\n",
              " 327: 'allow',\n",
              " 328: 'allowable',\n",
              " 329: 'allowance',\n",
              " 330: 'allowed',\n",
              " 331: 'allowing',\n",
              " 332: 'alltv',\n",
              " 333: 'alluded',\n",
              " 334: 'almaty',\n",
              " 335: 'almighty',\n",
              " 336: 'almirahs',\n",
              " 337: 'almost',\n",
              " 338: 'alms',\n",
              " 339: 'alois',\n",
              " 340: 'alone',\n",
              " 341: 'along',\n",
              " 342: 'alongside',\n",
              " 343: 'alps',\n",
              " 344: 'already',\n",
              " 345: 'also',\n",
              " 346: 'alter',\n",
              " 347: 'alteration',\n",
              " 348: 'altered',\n",
              " 349: 'alternate',\n",
              " 350: 'alternative',\n",
              " 351: 'alternatives',\n",
              " 352: 'although',\n",
              " 353: 'altitude',\n",
              " 354: 'alumni',\n",
              " 355: 'alveolar',\n",
              " 356: 'always',\n",
              " 357: 'am',\n",
              " 358: 'amah',\n",
              " 359: 'amalakas',\n",
              " 360: 'amartya',\n",
              " 361: 'amazement',\n",
              " 362: 'ambit',\n",
              " 363: 'ambitious',\n",
              " 364: 'ambush',\n",
              " 365: 'amended',\n",
              " 366: 'amenities',\n",
              " 367: 'america',\n",
              " 368: 'american',\n",
              " 369: 'americans',\n",
              " 370: 'americanused',\n",
              " 371: 'amino',\n",
              " 372: 'amitabh',\n",
              " 373: 'amitabha',\n",
              " 374: 'amma',\n",
              " 375: 'ammal',\n",
              " 376: 'amnesty',\n",
              " 377: 'amniotic',\n",
              " 378: 'among',\n",
              " 379: 'amongst',\n",
              " 380: 'amortization',\n",
              " 381: 'amos',\n",
              " 382: 'amount',\n",
              " 383: 'amounted',\n",
              " 384: 'amounting',\n",
              " 385: 'amplifies',\n",
              " 386: 'amravati',\n",
              " 387: 'amritsar',\n",
              " 388: 'amtur',\n",
              " 389: 'amylum',\n",
              " 390: 'an',\n",
              " 391: 'ana',\n",
              " 392: 'anachronistic',\n",
              " 393: 'analgesics',\n",
              " 394: 'analogy',\n",
              " 395: 'analysis',\n",
              " 396: 'analysts',\n",
              " 397: 'anandamoyi',\n",
              " 398: 'ananta',\n",
              " 399: 'anatomic',\n",
              " 400: 'ancestors',\n",
              " 401: 'ancient',\n",
              " 402: 'and',\n",
              " 403: 'andaman',\n",
              " 404: 'andhra',\n",
              " 405: 'andorran',\n",
              " 406: 'anemia',\n",
              " 407: 'anesthesia',\n",
              " 408: 'angel',\n",
              " 409: 'angeles',\n",
              " 410: 'angels',\n",
              " 411: 'angle',\n",
              " 412: 'anglicists',\n",
              " 413: 'anglo',\n",
              " 414: 'angloindian',\n",
              " 415: 'angry',\n",
              " 416: 'anguish',\n",
              " 417: 'anil',\n",
              " 418: 'animal',\n",
              " 419: 'animals',\n",
              " 420: 'animation',\n",
              " 421: 'anjar',\n",
              " 422: 'anjuta',\n",
              " 423: 'ankle',\n",
              " 424: 'annada',\n",
              " 425: 'annapurna',\n",
              " 426: 'anniversaries',\n",
              " 427: 'anniversary',\n",
              " 428: 'announced',\n",
              " 429: 'announcer',\n",
              " 430: 'annoyance',\n",
              " 431: 'annual',\n",
              " 432: 'annuities',\n",
              " 433: 'annulled',\n",
              " 434: 'another',\n",
              " 435: 'ansari',\n",
              " 436: 'ansicht',\n",
              " 437: 'answer',\n",
              " 438: 'answered',\n",
              " 439: 'answers',\n",
              " 440: 'ant',\n",
              " 441: 'antananarivo',\n",
              " 442: 'antarctic',\n",
              " 443: 'antarctica',\n",
              " 444: 'antariya',\n",
              " 445: 'antennae',\n",
              " 446: 'anthem',\n",
              " 447: 'anthony',\n",
              " 448: 'anthropologist',\n",
              " 449: 'anthropology',\n",
              " 450: 'anti',\n",
              " 451: 'antialiasing',\n",
              " 452: 'antiderivative',\n",
              " 453: 'antidote',\n",
              " 454: 'antipathy',\n",
              " 455: 'antipernicious',\n",
              " 456: 'antonym',\n",
              " 457: 'anu',\n",
              " 458: 'anuran',\n",
              " 459: 'anwar',\n",
              " 460: 'anxious',\n",
              " 461: 'any',\n",
              " 462: 'anybody',\n",
              " 463: 'anyhow',\n",
              " 464: 'anyone',\n",
              " 465: 'anything',\n",
              " 466: 'anyway',\n",
              " 467: 'aol',\n",
              " 468: 'aotus',\n",
              " 469: 'apace',\n",
              " 470: 'apart',\n",
              " 471: 'apartheid',\n",
              " 472: 'apathy',\n",
              " 473: 'apes',\n",
              " 474: 'apex',\n",
              " 475: 'api',\n",
              " 476: 'apiculture',\n",
              " 477: 'aponline',\n",
              " 478: 'apostle',\n",
              " 479: 'apostles',\n",
              " 480: 'apostle’s',\n",
              " 481: 'app',\n",
              " 482: 'appar',\n",
              " 483: 'apparently',\n",
              " 484: 'appeal',\n",
              " 485: 'appeals',\n",
              " 486: 'appear',\n",
              " 487: 'appearance',\n",
              " 488: 'appeared',\n",
              " 489: 'appears',\n",
              " 490: 'appease',\n",
              " 491: 'appellant',\n",
              " 492: 'appellate',\n",
              " 493: 'append',\n",
              " 494: 'appending',\n",
              " 495: 'appendix',\n",
              " 496: 'appetite',\n",
              " 497: 'applaudable',\n",
              " 498: 'applauded',\n",
              " 499: 'applause',\n",
              " 500: 'apple',\n",
              " 501: 'applet',\n",
              " 502: 'applicable',\n",
              " 503: 'applicantthe',\n",
              " 504: 'application',\n",
              " 505: 'applications',\n",
              " 506: 'applied',\n",
              " 507: 'applies',\n",
              " 508: 'apply',\n",
              " 509: 'applying',\n",
              " 510: 'appoinment',\n",
              " 511: 'appoint',\n",
              " 512: 'appointed',\n",
              " 513: 'appointment',\n",
              " 514: 'appraisals',\n",
              " 515: 'appreciate',\n",
              " 516: 'appreciated',\n",
              " 517: 'appreciating',\n",
              " 518: 'appreciation',\n",
              " 519: 'apprehended',\n",
              " 520: 'approach',\n",
              " 521: 'approached',\n",
              " 522: 'approaches',\n",
              " 523: 'approaching',\n",
              " 524: 'appropriated',\n",
              " 525: 'approval',\n",
              " 526: 'approved',\n",
              " 527: 'approximate',\n",
              " 528: 'approximately',\n",
              " 529: 'approximation',\n",
              " 530: 'apps',\n",
              " 531: 'april',\n",
              " 532: 'apt',\n",
              " 533: 'aquatic',\n",
              " 534: 'arab',\n",
              " 535: 'arabic',\n",
              " 536: 'arbitral',\n",
              " 537: 'arbitrary',\n",
              " 538: 'arbitration',\n",
              " 539: 'arbitrator',\n",
              " 540: 'arbitrators',\n",
              " 541: 'archaeological',\n",
              " 542: 'archaeology',\n",
              " 543: 'arches',\n",
              " 544: 'archimedes',\n",
              " 545: 'architecture',\n",
              " 546: 'are',\n",
              " 547: 'area',\n",
              " 548: 'areas',\n",
              " 549: 'areopagitica',\n",
              " 550: 'arg',\n",
              " 551: 'argentina',\n",
              " 552: 'argue',\n",
              " 553: 'argued',\n",
              " 554: 'argues',\n",
              " 555: 'argument',\n",
              " 556: 'argyle',\n",
              " 557: 'arim',\n",
              " 558: 'arise',\n",
              " 559: 'aristocratic',\n",
              " 560: 'arithmetic',\n",
              " 561: 'arithmetical',\n",
              " 562: 'arkansas',\n",
              " 563: 'armed',\n",
              " 564: 'armenian',\n",
              " 565: 'armies',\n",
              " 566: 'armlet',\n",
              " 567: 'arms',\n",
              " 568: 'armscii',\n",
              " 569: 'army',\n",
              " 570: 'aromatic',\n",
              " 571: 'aromaticum',\n",
              " 572: 'around',\n",
              " 573: 'aroused',\n",
              " 574: 'arranged',\n",
              " 575: 'arrangement',\n",
              " 576: 'arrangements',\n",
              " 577: 'arranta',\n",
              " 578: 'arraying',\n",
              " 579: 'arrears',\n",
              " 580: 'arrest',\n",
              " 581: 'arrested',\n",
              " 582: 'arrests',\n",
              " 583: 'arrival',\n",
              " 584: 'arrivals',\n",
              " 585: 'arrive',\n",
              " 586: 'arrived',\n",
              " 587: 'arriving',\n",
              " 588: 'arrogant',\n",
              " 589: 'arrow',\n",
              " 590: 'arrows',\n",
              " 591: 'arrr',\n",
              " 592: 'arsenic',\n",
              " 593: 'art',\n",
              " 594: 'arteries',\n",
              " 595: 'arthropod',\n",
              " 596: 'arthropods',\n",
              " 597: 'article',\n",
              " 598: 'articles',\n",
              " 599: 'articulate',\n",
              " 600: 'artisans',\n",
              " 601: 'artist',\n",
              " 602: 'artists',\n",
              " 603: 'arts',\n",
              " 604: 'arun',\n",
              " 605: 'aryan',\n",
              " 606: 'as',\n",
              " 607: 'asa',\n",
              " 608: 'asar',\n",
              " 609: 'ascendency',\n",
              " 610: 'ascending',\n",
              " 611: 'ascent',\n",
              " 612: 'ascetic',\n",
              " 613: 'ascii',\n",
              " 614: 'ascribe',\n",
              " 615: 'ascribed',\n",
              " 616: 'ascribes',\n",
              " 617: 'ashamedp',\n",
              " 618: 'ashes',\n",
              " 619: 'ashrushti',\n",
              " 620: 'ashutosh',\n",
              " 621: 'asia',\n",
              " 622: 'asian',\n",
              " 623: 'asians',\n",
              " 624: 'asiatic',\n",
              " 625: 'aside',\n",
              " 626: 'ask',\n",
              " 627: 'asked',\n",
              " 628: 'asking',\n",
              " 629: 'asom',\n",
              " 630: 'asparagus',\n",
              " 631: 'aspect',\n",
              " 632: 'aspects',\n",
              " 633: 'aspergery',\n",
              " 634: 'aspiration',\n",
              " 635: 'aspirations',\n",
              " 636: 'aspire',\n",
              " 637: 'ass',\n",
              " 638: 'assam',\n",
              " 639: 'assembled',\n",
              " 640: 'assemblies',\n",
              " 641: 'assembly',\n",
              " 642: 'assent',\n",
              " 643: 'assert',\n",
              " 644: 'asserted',\n",
              " 645: 'assertion',\n",
              " 646: 'assess',\n",
              " 647: 'assessed',\n",
              " 648: 'assessee',\n",
              " 649: 'assesses',\n",
              " 650: 'assessing',\n",
              " 651: 'assessment',\n",
              " 652: 'asset',\n",
              " 653: 'assets',\n",
              " 654: 'asshole',\n",
              " 655: 'assigned',\n",
              " 656: 'assist',\n",
              " 657: 'assistance',\n",
              " 658: 'assistant',\n",
              " 659: 'assistants',\n",
              " 660: 'assisting',\n",
              " 661: 'associate',\n",
              " 662: 'associated',\n",
              " 663: 'associates',\n",
              " 664: 'association',\n",
              " 665: 'associations',\n",
              " 666: 'assume',\n",
              " 667: 'assumed',\n",
              " 668: 'assured',\n",
              " 669: 'assuredly',\n",
              " 670: 'astama',\n",
              " 671: 'asthenia',\n",
              " 672: 'astra',\n",
              " 673: 'astray',\n",
              " 674: 'astute',\n",
              " 675: 'asunder',\n",
              " 676: 'asurl',\n",
              " 677: 'asutosh',\n",
              " 678: 'aswaghosa',\n",
              " 679: 'asymptomatic',\n",
              " 680: 'asymptotically',\n",
              " 681: 'as…',\n",
              " 682: 'at',\n",
              " 683: 'ataxia',\n",
              " 684: 'ate',\n",
              " 685: 'athene',\n",
              " 686: 'atikokan',\n",
              " 687: 'atleast',\n",
              " 688: 'atm',\n",
              " 689: 'atmosphere',\n",
              " 690: 'atmospheric',\n",
              " 691: 'atoms',\n",
              " 692: 'atone',\n",
              " 693: 'atones',\n",
              " 694: 'attach',\n",
              " 695: 'attached',\n",
              " 696: 'attaches',\n",
              " 697: 'attachment',\n",
              " 698: 'attack',\n",
              " 699: 'attacked',\n",
              " 700: 'attacks',\n",
              " 701: 'attain',\n",
              " 702: 'attained',\n",
              " 703: 'attaining',\n",
              " 704: 'attainments',\n",
              " 705: 'attains',\n",
              " 706: 'attempt',\n",
              " 707: 'attempted',\n",
              " 708: 'attempts',\n",
              " 709: 'attend',\n",
              " 710: 'attendance',\n",
              " 711: 'attendants',\n",
              " 712: 'attended',\n",
              " 713: 'attendees',\n",
              " 714: 'attention',\n",
              " 715: 'attitude',\n",
              " 716: 'attitudes',\n",
              " 717: 'attorney',\n",
              " 718: 'attract',\n",
              " 719: 'attracted',\n",
              " 720: 'attractions',\n",
              " 721: 'attributable',\n",
              " 722: 'attribute',\n",
              " 723: 'attuc',\n",
              " 724: 'atualizar',\n",
              " 725: 'atulya',\n",
              " 726: 'auction',\n",
              " 727: 'audio',\n",
              " 728: 'audiogram',\n",
              " 729: 'audit',\n",
              " 730: 'audrey',\n",
              " 731: 'aught',\n",
              " 732: 'augment',\n",
              " 733: 'augmenting',\n",
              " 734: 'august',\n",
              " 735: 'augustin',\n",
              " 736: 'aun',\n",
              " 737: 'aurorae',\n",
              " 738: 'auroville',\n",
              " 739: 'auspicious',\n",
              " 740: 'australia',\n",
              " 741: 'austria',\n",
              " 742: 'authentication',\n",
              " 743: 'author',\n",
              " 744: 'authorisation',\n",
              " 745: 'authorisations',\n",
              " 746: 'authorised',\n",
              " 747: 'authoritarianism',\n",
              " 748: 'authorities',\n",
              " 749: 'authority',\n",
              " 750: 'authors',\n",
              " 751: 'autism',\n",
              " 752: 'auto',\n",
              " 753: 'autodiscover',\n",
              " 754: 'automatic',\n",
              " 755: 'automatically',\n",
              " 756: 'automobile',\n",
              " 757: 'automobiles',\n",
              " 758: 'automount',\n",
              " 759: 'autonomous',\n",
              " 760: 'autonomy',\n",
              " 761: 'autopolyploidy',\n",
              " 762: 'autoprobed',\n",
              " 763: 'avail',\n",
              " 764: 'availability',\n",
              " 765: 'available',\n",
              " 766: 'availed',\n",
              " 767: 'avatar',\n",
              " 768: 'average',\n",
              " 769: 'averters',\n",
              " 770: 'aviation',\n",
              " 771: 'avner',\n",
              " 772: 'avoid',\n",
              " 773: 'avoidance',\n",
              " 774: 'avoided',\n",
              " 775: 'awadh',\n",
              " 776: 'awaited',\n",
              " 777: 'awaits',\n",
              " 778: 'awake',\n",
              " 779: 'award',\n",
              " 780: 'awarded',\n",
              " 781: 'awards',\n",
              " 782: 'aware',\n",
              " 783: 'awareness',\n",
              " 784: 'away',\n",
              " 785: 'awful',\n",
              " 786: 'awlaki',\n",
              " 787: 'axes',\n",
              " 788: 'axis',\n",
              " 789: 'ayat',\n",
              " 790: 'aye',\n",
              " 791: 'ayesha',\n",
              " 792: 'ayodhya',\n",
              " 793: 'ayora',\n",
              " 794: 'ayrıldı',\n",
              " 795: 'ayurveda',\n",
              " 796: 'azar',\n",
              " 797: 'aziz',\n",
              " 798: 'aztec',\n",
              " 799: 'à',\n",
              " 800: 'b',\n",
              " 801: 'ba',\n",
              " 802: 'baad',\n",
              " 803: 'baat',\n",
              " 804: 'baaten',\n",
              " 805: 'baazi',\n",
              " 806: 'baba',\n",
              " 807: 'babariawad',\n",
              " 808: 'babu',\n",
              " 809: 'baby',\n",
              " 810: 'babylonia',\n",
              " 811: 'bacchan',\n",
              " 812: 'bachchan',\n",
              " 813: 'bachelor',\n",
              " 814: 'bachendri',\n",
              " 815: 'bachhan',\n",
              " 816: 'back',\n",
              " 817: 'background',\n",
              " 818: 'backlogsomewhat',\n",
              " 819: 'backoff',\n",
              " 820: 'backup',\n",
              " 821: 'backward',\n",
              " 822: 'bacteria',\n",
              " 823: 'bad',\n",
              " 824: 'badh',\n",
              " 825: 'badly',\n",
              " 826: 'bag',\n",
              " 827: 'bagh',\n",
              " 828: 'baghban',\n",
              " 829: 'baghdad',\n",
              " 830: 'bahadur',\n",
              " 831: 'baham',\n",
              " 832: 'bahamani',\n",
              " 833: 'bahinse“”',\n",
              " 834: 'bahraich',\n",
              " 835: 'bail',\n",
              " 836: 'bailiff',\n",
              " 837: 'bailment',\n",
              " 838: 'bajirao',\n",
              " 839: 'bal',\n",
              " 840: 'balance',\n",
              " 841: 'balanced',\n",
              " 842: 'balancing',\n",
              " 843: 'balappa',\n",
              " 844: 'balaram',\n",
              " 845: 'balarama',\n",
              " 846: 'bald',\n",
              " 847: 'balkh',\n",
              " 848: 'ball',\n",
              " 849: 'bamboo',\n",
              " 850: 'banana',\n",
              " 851: 'band',\n",
              " 852: 'bande',\n",
              " 853: 'banded',\n",
              " 854: 'bandha',\n",
              " 855: 'bandimet',\n",
              " 856: 'banerjee',\n",
              " 857: 'bangadarsan',\n",
              " 858: 'bangalore',\n",
              " 859: 'bangaluru',\n",
              " 860: 'bangladesh',\n",
              " 861: 'banhi',\n",
              " 862: 'bank',\n",
              " 863: 'bankim',\n",
              " 864: 'bankimchandra',\n",
              " 865: 'banking',\n",
              " 866: 'banknotes',\n",
              " 867: 'bankruptcy',\n",
              " 868: 'banks',\n",
              " 869: 'banner',\n",
              " 870: 'bannister',\n",
              " 871: 'banquet',\n",
              " 872: 'banyan',\n",
              " 873: 'bapu',\n",
              " 874: 'bapusaheb',\n",
              " 875: 'bar',\n",
              " 876: 'bara',\n",
              " 877: 'barbarism',\n",
              " 878: 'barco',\n",
              " 879: 'bare',\n",
              " 880: 'barefoot',\n",
              " 881: 'barely',\n",
              " 882: 'barfi',\n",
              " 883: 'bargaining',\n",
              " 884: 'bargains',\n",
              " 885: 'barley',\n",
              " 886: 'barowari',\n",
              " 887: 'barratry',\n",
              " 888: 'barren',\n",
              " 889: 'barricade',\n",
              " 890: 'barristers',\n",
              " 891: 'bars',\n",
              " 892: 'basal',\n",
              " 893: 'base',\n",
              " 894: 'based',\n",
              " 895: 'bash',\n",
              " 896: 'basic',\n",
              " 897: 'basically',\n",
              " 898: 'basin',\n",
              " 899: 'basis',\n",
              " 900: 'basket',\n",
              " 901: 'başka',\n",
              " 902: 'bath',\n",
              " 903: 'bathroom',\n",
              " 904: 'battalion',\n",
              " 905: 'battalions',\n",
              " 906: 'battering',\n",
              " 907: 'battery',\n",
              " 908: 'battle',\n",
              " 909: 'battlefield',\n",
              " 910: 'battles',\n",
              " 911: 'battling',\n",
              " 912: 'bay',\n",
              " 913: 'bc',\n",
              " 914: 'be',\n",
              " 915: 'beacon',\n",
              " 916: 'bear',\n",
              " 917: 'bearer',\n",
              " 918: 'beareth',\n",
              " 919: 'bearing',\n",
              " 920: 'beasts',\n",
              " 921: 'beaten',\n",
              " 922: 'beating',\n",
              " 923: 'beats',\n",
              " 924: 'beautiful',\n",
              " 925: 'beautifully',\n",
              " 926: 'beauty',\n",
              " 927: 'became',\n",
              " 928: 'because',\n",
              " 929: 'become',\n",
              " 930: 'becomes',\n",
              " 931: 'becometh',\n",
              " 932: 'becoming',\n",
              " 933: 'bed',\n",
              " 934: 'bedsheet',\n",
              " 935: 'been',\n",
              " 936: 'befallen',\n",
              " 937: 'befalls',\n",
              " 938: 'befell',\n",
              " 939: 'before',\n",
              " 940: 'began',\n",
              " 941: 'begets',\n",
              " 942: 'beggar',\n",
              " 943: 'begging',\n",
              " 944: 'begin',\n",
              " 945: 'beginner',\n",
              " 946: 'beginning',\n",
              " 947: 'beginnings',\n",
              " 948: 'begins',\n",
              " 949: 'begotten',\n",
              " 950: 'behalf',\n",
              " 951: 'behave',\n",
              " 952: 'behaved',\n",
              " 953: 'behavior',\n",
              " 954: 'behaviour',\n",
              " 955: 'beheaded',\n",
              " 956: 'beheld',\n",
              " 957: 'behind',\n",
              " 958: 'behold',\n",
              " 959: 'being',\n",
              " 960: 'beings',\n",
              " 961: 'bejoy',\n",
              " 962: 'bekaner',\n",
              " 963: 'belarus',\n",
              " 964: 'belarusian',\n",
              " 965: 'belgachia',\n",
              " 966: 'belgaum',\n",
              " 967: 'belgian',\n",
              " 968: 'belie',\n",
              " 969: 'belied',\n",
              " 970: 'belief',\n",
              " 971: 'beliefs',\n",
              " 972: 'believe',\n",
              " 973: 'believed',\n",
              " 974: 'believer',\n",
              " 975: 'believers',\n",
              " 976: 'believes',\n",
              " 977: 'believing',\n",
              " 978: 'bella',\n",
              " 979: 'belong',\n",
              " 980: 'belonging',\n",
              " 981: 'belongings',\n",
              " 982: 'belongs',\n",
              " 983: 'belonolaimidae',\n",
              " 984: 'belorussian',\n",
              " 985: 'beloved',\n",
              " 986: 'below',\n",
              " 987: 'ben',\n",
              " 988: 'beneath',\n",
              " 989: 'beneficent',\n",
              " 990: 'beneficial',\n",
              " 991: 'benefit',\n",
              " 992: 'benefits',\n",
              " 993: 'benefitted',\n",
              " 994: 'benevolence',\n",
              " 995: 'bengal',\n",
              " 996: 'bengalensis',\n",
              " 997: 'bengali',\n",
              " 998: 'bengalis',\n",
              " 999: 'beoti',\n",
              " 1000: 'berkshire',\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "reverse_input_char_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "1_faQ1HMZxR-",
        "outputId": "eab219b1-a448-4dd0-f418-dbb563a54f73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                          hindi                                                                          english  length_eng  length_hin\n",
              "0   START_ तो लघुतम संपवर्तक होगा—क्यूंकी इन _END                                so the least common multiple is going to be because these                        11          7         \n",
              "2   START_ प्रयोग के लिए इकाई जब तापमान दिखाया जा रहा हो _END                    the unit to use when showing temperatures                                        7           12        \n",
              "3   START_ और जिन्हें तुम पूजते हो मैं उनका पूजने वाला नहीं _END                 nor am i worshiping what you have worshipped                                     8           12        \n",
              "4   START_ सिनसिनाटी मास्टर्स _END                                               cincinnati open                                                                  2           4         \n",
              "5   START_ और शैतान तुम्हें रोक न दे निश्चय ही वह तुम्हारा खुला शत्रु है _END    let not satan bar you he is for you a manifest foe                               12          15        \n",
              "6   START_ विरूद्धार्थी _END                                                     antonym                                                                          1           3         \n",
              "8   START_ विभिन्न औषधी आवृत्ति और हमलों की गंभीरता के आधार पर ली जाती है। _END  different drugs are used depending on the frequency and severity of the attacks  13          15        \n",
              "9   START_ असाई _END                                                             rude                                                                             1           3         \n",
              "12  START_ अध्ययन सामग्री के डिस्पैच के सत्र के लिए धारा के लिए स्थिति _END      status of dispatch of study material for stream for the session                  11          14        \n",
              "13  START_ भारत का हस्तशिल्प निर्यात _END                                        indian handicraft industry                                                       3           6         "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-677635cc-18f8-4df7-90f4-a4c30f9cc464\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hindi</th>\n",
              "      <th>english</th>\n",
              "      <th>length_eng</th>\n",
              "      <th>length_hin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>START_ तो लघुतम संपवर्तक होगा—क्यूंकी इन _END</td>\n",
              "      <td>so the least common multiple is going to be because these</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>START_ प्रयोग के लिए इकाई जब तापमान दिखाया जा रहा हो _END</td>\n",
              "      <td>the unit to use when showing temperatures</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>START_ और जिन्हें तुम पूजते हो मैं उनका पूजने वाला नहीं _END</td>\n",
              "      <td>nor am i worshiping what you have worshipped</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>START_ सिनसिनाटी मास्टर्स _END</td>\n",
              "      <td>cincinnati open</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>START_ और शैतान तुम्हें रोक न दे निश्चय ही वह तुम्हारा खुला शत्रु है _END</td>\n",
              "      <td>let not satan bar you he is for you a manifest foe</td>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>START_ विरूद्धार्थी _END</td>\n",
              "      <td>antonym</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>START_ विभिन्न औषधी आवृत्ति और हमलों की गंभीरता के आधार पर ली जाती है। _END</td>\n",
              "      <td>different drugs are used depending on the frequency and severity of the attacks</td>\n",
              "      <td>13</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>START_ असाई _END</td>\n",
              "      <td>rude</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>START_ अध्ययन सामग्री के डिस्पैच के सत्र के लिए धारा के लिए स्थिति _END</td>\n",
              "      <td>status of dispatch of study material for stream for the session</td>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>START_ भारत का हस्तशिल्प निर्यात _END</td>\n",
              "      <td>indian handicraft industry</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-677635cc-18f8-4df7-90f4-a4c30f9cc464')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-677635cc-18f8-4df7-90f4-a4c30f9cc464 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-677635cc-18f8-4df7-90f4-a4c30f9cc464');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7311c02f-23cb-4856-81ed-0c8849bfd6b5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7311c02f-23cb-4856-81ed-0c8849bfd6b5')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7311c02f-23cb-4856-81ed-0c8849bfd6b5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "lines.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3CO-JQhZx9C",
        "outputId": "aa136eba-7786-4912-b81f-4a578420a410"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2972,), (744,))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X, y = lines['english'], lines['hindi']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMDQ_LqpZ1Rg",
        "outputId": "7dcb0363-a01e-48c6-d352-264f69e13f7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2652    a momentary spasmodic contraction of a muscle fiber\n",
              "788     emanuele tamponi                                   \n",
              "2279    and b i don t even hang out with people like that  \n",
              "3951    douglas devananda                                  \n",
              "392     hellenic                                           \n",
              "          ...                                              \n",
              "1511    tart                                               \n",
              "1731    for the benefit of prospective entrepreneurs       \n",
              "1142    renchi raju                                        \n",
              "4730    lop buri                                           \n",
              "4289    file s could not be opened s                       \n",
              "Name: english, Length: 2972, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "7czXwRVdZ2vq"
      },
      "outputs": [],
      "source": [
        "encoder_input_data = np.zeros((2, max_length_src),dtype='float32')\n",
        "decoder_input_data = np.zeros((2, max_length_tar),dtype='float32')\n",
        "decoder_target_data = np.zeros((2, max_length_tar, num_decoder_tokens),dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "-xRMHx_XZ4V8"
      },
      "outputs": [],
      "source": [
        "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
        "    ''' Generate a batch of data '''\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text.split()):\n",
        "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
        "                for t, word in enumerate(target_text.split()):\n",
        "                    if t<len(target_text.split())-1:\n",
        "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
        "                    if t>0:\n",
        "                        # decoder target sequence (one hot encoded)\n",
        "                        # does not include the START_ token\n",
        "                        # Offset by one timestep\n",
        "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "4_VC2fw8Z58a"
      },
      "outputs": [],
      "source": [
        "latent_dim = 300\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb =  Embedding(num_encoder_tokens+1, latent_dim, mask_zero = True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "aHZ_Bk2TZ8YO"
      },
      "outputs": [],
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(num_decoder_tokens+1, latent_dim, mask_zero = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "4c_TS_b5aCIU"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGIMvFZraDd4",
        "outputId": "451e070b-7a12-4a19-9ce1-d891b0972472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 300)    3308100     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 300)    3968700     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 300),        721200      ['embedding[0][0]']              \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 300),  721200      ['embedding_1[0][0]',            \n",
            "                                 (None, 300),                     'lstm[0][1]',                   \n",
            "                                 (None, 300)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 13228)  3981628     ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 12,700,828\n",
            "Trainable params: 12,700,828\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()\n",
        "train_samples = len(X_train)\n",
        "val_samples = len(X_test)\n",
        "batch_size = 64\n",
        "epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "gSsc4yFEaFE7"
      },
      "outputs": [],
      "source": [
        "model.save('eng-to-hindi.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "hu5bYiudaGX-"
      },
      "outputs": [],
      "source": [
        "a, b = next(generate_batch())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJp7Vz3waICB",
        "outputId": "584c920b-bcad-4dde-aa72-e55513837c40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 1., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 1., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCb21MxnaJkE",
        "outputId": "07b0a359-0c60-4e26-b193-8a95b95f7171"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-48-251c55099ab9>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 38s 503ms/step - loss: 8.1179 - accuracy: 0.1358 - val_loss: 7.3408 - val_accuracy: 0.1434\n",
            "Epoch 2/100\n",
            "46/46 [==============================] - 7s 156ms/step - loss: 6.7636 - accuracy: 0.1477 - val_loss: 7.3018 - val_accuracy: 0.1563\n",
            "Epoch 3/100\n",
            "46/46 [==============================] - 6s 138ms/step - loss: 6.4377 - accuracy: 0.1572 - val_loss: 7.2683 - val_accuracy: 0.1590\n",
            "Epoch 4/100\n",
            "46/46 [==============================] - 7s 153ms/step - loss: 6.2136 - accuracy: 0.1600 - val_loss: 7.3267 - val_accuracy: 0.1595\n",
            "Epoch 5/100\n",
            "46/46 [==============================] - 6s 141ms/step - loss: 6.0360 - accuracy: 0.1647 - val_loss: 7.3973 - val_accuracy: 0.1576\n",
            "Epoch 6/100\n",
            "46/46 [==============================] - 8s 167ms/step - loss: 5.8924 - accuracy: 0.1689 - val_loss: 7.4734 - val_accuracy: 0.1578\n",
            "Epoch 7/100\n",
            "46/46 [==============================] - 8s 168ms/step - loss: 5.7553 - accuracy: 0.1741 - val_loss: 7.5328 - val_accuracy: 0.1611\n",
            "Epoch 8/100\n",
            "46/46 [==============================] - 6s 140ms/step - loss: 5.6200 - accuracy: 0.1797 - val_loss: 7.6209 - val_accuracy: 0.1618\n",
            "Epoch 9/100\n",
            "46/46 [==============================] - 7s 156ms/step - loss: 5.4921 - accuracy: 0.1854 - val_loss: 7.6661 - val_accuracy: 0.1686\n",
            "Epoch 10/100\n",
            "46/46 [==============================] - 6s 138ms/step - loss: 5.3617 - accuracy: 0.1927 - val_loss: 7.7198 - val_accuracy: 0.1630\n",
            "Epoch 11/100\n",
            "46/46 [==============================] - 7s 154ms/step - loss: 5.2295 - accuracy: 0.1991 - val_loss: 7.8001 - val_accuracy: 0.1605\n",
            "Epoch 12/100\n",
            "46/46 [==============================] - 7s 141ms/step - loss: 5.0958 - accuracy: 0.2043 - val_loss: 7.9136 - val_accuracy: 0.1618\n",
            "Epoch 13/100\n",
            "46/46 [==============================] - 7s 153ms/step - loss: 4.9822 - accuracy: 0.2099 - val_loss: 7.9794 - val_accuracy: 0.1638\n",
            "Epoch 14/100\n",
            "46/46 [==============================] - 8s 169ms/step - loss: 4.8457 - accuracy: 0.2157 - val_loss: 7.9733 - val_accuracy: 0.1703\n",
            "Epoch 15/100\n",
            "46/46 [==============================] - 6s 141ms/step - loss: 4.7002 - accuracy: 0.2244 - val_loss: 8.0583 - val_accuracy: 0.1684\n",
            "Epoch 16/100\n",
            "46/46 [==============================] - 7s 155ms/step - loss: 4.5713 - accuracy: 0.2320 - val_loss: 8.1462 - val_accuracy: 0.1615\n",
            "Epoch 17/100\n",
            "46/46 [==============================] - 6s 141ms/step - loss: 4.4440 - accuracy: 0.2409 - val_loss: 8.2133 - val_accuracy: 0.1580\n",
            "Epoch 18/100\n",
            "46/46 [==============================] - 7s 152ms/step - loss: 4.3139 - accuracy: 0.2509 - val_loss: 8.2707 - val_accuracy: 0.1636\n",
            "Epoch 19/100\n",
            "46/46 [==============================] - 7s 141ms/step - loss: 4.1822 - accuracy: 0.2605 - val_loss: 8.3751 - val_accuracy: 0.1651\n",
            "Epoch 20/100\n",
            "46/46 [==============================] - 7s 152ms/step - loss: 4.0504 - accuracy: 0.2711 - val_loss: 8.4844 - val_accuracy: 0.1628\n",
            "Epoch 21/100\n",
            "46/46 [==============================] - 7s 143ms/step - loss: 3.9186 - accuracy: 0.2830 - val_loss: 8.5408 - val_accuracy: 0.1665\n",
            "Epoch 22/100\n",
            "46/46 [==============================] - 7s 148ms/step - loss: 3.7892 - accuracy: 0.2970 - val_loss: 8.5933 - val_accuracy: 0.1665\n",
            "Epoch 23/100\n",
            "46/46 [==============================] - 8s 175ms/step - loss: 3.6636 - accuracy: 0.3124 - val_loss: 8.6720 - val_accuracy: 0.1622\n",
            "Epoch 24/100\n",
            "46/46 [==============================] - 6s 138ms/step - loss: 3.5352 - accuracy: 0.3290 - val_loss: 8.7237 - val_accuracy: 0.1617\n",
            "Epoch 25/100\n",
            "46/46 [==============================] - 7s 155ms/step - loss: 3.4108 - accuracy: 0.3467 - val_loss: 8.7633 - val_accuracy: 0.1644\n",
            "Epoch 26/100\n",
            "46/46 [==============================] - 6s 138ms/step - loss: 3.2940 - accuracy: 0.3656 - val_loss: 8.8588 - val_accuracy: 0.1676\n",
            "Epoch 27/100\n",
            "46/46 [==============================] - 7s 153ms/step - loss: 3.1877 - accuracy: 0.3852 - val_loss: 8.8826 - val_accuracy: 0.1663\n",
            "Epoch 28/100\n",
            "46/46 [==============================] - 6s 140ms/step - loss: 3.0651 - accuracy: 0.4092 - val_loss: 8.8947 - val_accuracy: 0.1570\n",
            "Epoch 29/100\n",
            "46/46 [==============================] - 7s 154ms/step - loss: 2.9352 - accuracy: 0.4323 - val_loss: 8.9087 - val_accuracy: 0.1584\n",
            "Epoch 30/100\n",
            "46/46 [==============================] - 8s 167ms/step - loss: 2.8086 - accuracy: 0.4652 - val_loss: 8.9848 - val_accuracy: 0.1597\n",
            "Epoch 31/100\n",
            "46/46 [==============================] - 6s 138ms/step - loss: 2.6793 - accuracy: 0.4927 - val_loss: 9.0466 - val_accuracy: 0.1638\n",
            "Epoch 32/100\n",
            "46/46 [==============================] - 7s 156ms/step - loss: 2.5476 - accuracy: 0.5240 - val_loss: 9.1070 - val_accuracy: 0.1647\n",
            "Epoch 33/100\n",
            "46/46 [==============================] - 6s 140ms/step - loss: 2.4183 - accuracy: 0.5530 - val_loss: 9.1846 - val_accuracy: 0.1671\n",
            "Epoch 34/100\n",
            "46/46 [==============================] - 7s 152ms/step - loss: 2.2902 - accuracy: 0.5807 - val_loss: 9.2435 - val_accuracy: 0.1674\n",
            "Epoch 35/100\n",
            "46/46 [==============================] - 7s 142ms/step - loss: 2.1719 - accuracy: 0.6078 - val_loss: 9.2834 - val_accuracy: 0.1674\n",
            "Epoch 36/100\n",
            "46/46 [==============================] - 7s 153ms/step - loss: 2.0580 - accuracy: 0.6326 - val_loss: 9.2973 - val_accuracy: 0.1651\n",
            "Epoch 37/100\n",
            "46/46 [==============================] - 8s 172ms/step - loss: 1.9457 - accuracy: 0.6560 - val_loss: 9.3858 - val_accuracy: 0.1703\n",
            "Epoch 38/100\n",
            "46/46 [==============================] - 6s 138ms/step - loss: 1.8439 - accuracy: 0.6774 - val_loss: 9.4126 - val_accuracy: 0.1703\n",
            "Epoch 39/100\n",
            "46/46 [==============================] - 7s 156ms/step - loss: 1.7499 - accuracy: 0.6957 - val_loss: 9.4386 - val_accuracy: 0.1661\n",
            "Epoch 40/100\n",
            "46/46 [==============================] - 6s 140ms/step - loss: 1.6525 - accuracy: 0.7156 - val_loss: 9.5053 - val_accuracy: 0.1682\n",
            "Epoch 41/100\n",
            "46/46 [==============================] - 7s 156ms/step - loss: 1.5537 - accuracy: 0.7382 - val_loss: 9.5884 - val_accuracy: 0.1724\n",
            "Epoch 42/100\n",
            "46/46 [==============================] - 7s 141ms/step - loss: 1.4731 - accuracy: 0.7539 - val_loss: 9.5850 - val_accuracy: 0.1699\n",
            "Epoch 43/100\n",
            "46/46 [==============================] - 7s 156ms/step - loss: 1.3954 - accuracy: 0.7708 - val_loss: 9.6485 - val_accuracy: 0.1699\n",
            "Epoch 44/100\n",
            "46/46 [==============================] - 7s 158ms/step - loss: 1.3178 - accuracy: 0.7864 - val_loss: 9.6899 - val_accuracy: 0.1697\n",
            "Epoch 45/100\n",
            "46/46 [==============================] - 7s 152ms/step - loss: 1.2421 - accuracy: 0.8020 - val_loss: 9.7008 - val_accuracy: 0.1699\n",
            "Epoch 46/100\n",
            "46/46 [==============================] - 7s 154ms/step - loss: 1.1726 - accuracy: 0.8153 - val_loss: 9.7321 - val_accuracy: 0.1694\n",
            "Epoch 47/100\n",
            "46/46 [==============================] - 7s 141ms/step - loss: 1.0996 - accuracy: 0.8284 - val_loss: 9.7823 - val_accuracy: 0.1703\n",
            "Epoch 48/100\n",
            "46/46 [==============================] - 7s 156ms/step - loss: 1.0289 - accuracy: 0.8407 - val_loss: 9.8407 - val_accuracy: 0.1696\n",
            "Epoch 49/100\n",
            "46/46 [==============================] - 6s 141ms/step - loss: 0.9642 - accuracy: 0.8536 - val_loss: 9.8727 - val_accuracy: 0.1655\n",
            "Epoch 50/100\n",
            "46/46 [==============================] - 7s 157ms/step - loss: 0.9043 - accuracy: 0.8650 - val_loss: 9.8909 - val_accuracy: 0.1657\n",
            "Epoch 51/100\n",
            "46/46 [==============================] - 6s 140ms/step - loss: 0.8481 - accuracy: 0.8747 - val_loss: 9.9069 - val_accuracy: 0.1640\n",
            "Epoch 52/100\n",
            "46/46 [==============================] - 7s 152ms/step - loss: 0.7956 - accuracy: 0.8851 - val_loss: 9.9313 - val_accuracy: 0.1640\n",
            "Epoch 53/100\n",
            "46/46 [==============================] - 8s 171ms/step - loss: 0.7464 - accuracy: 0.8944 - val_loss: 9.9787 - val_accuracy: 0.1655\n",
            "Epoch 54/100\n",
            "46/46 [==============================] - 7s 142ms/step - loss: 0.7008 - accuracy: 0.9023 - val_loss: 10.0539 - val_accuracy: 0.1692\n",
            "Epoch 55/100\n",
            "46/46 [==============================] - 7s 155ms/step - loss: 0.6606 - accuracy: 0.9107 - val_loss: 10.0810 - val_accuracy: 0.1707\n",
            "Epoch 56/100\n",
            "46/46 [==============================] - 6s 140ms/step - loss: 0.6246 - accuracy: 0.9168 - val_loss: 10.0895 - val_accuracy: 0.1692\n",
            "Epoch 57/100\n",
            "46/46 [==============================] - 7s 154ms/step - loss: 0.5855 - accuracy: 0.9237 - val_loss: 10.1411 - val_accuracy: 0.1721\n",
            "Epoch 58/100\n",
            "46/46 [==============================] - 7s 141ms/step - loss: 0.5510 - accuracy: 0.9300 - val_loss: 10.1514 - val_accuracy: 0.1703\n",
            "Epoch 59/100\n",
            "46/46 [==============================] - 7s 153ms/step - loss: 0.5183 - accuracy: 0.9359 - val_loss: 10.1865 - val_accuracy: 0.1686\n",
            "Epoch 60/100\n",
            "46/46 [==============================] - 7s 142ms/step - loss: 0.4848 - accuracy: 0.9422 - val_loss: 10.2358 - val_accuracy: 0.1730\n",
            "Epoch 61/100\n",
            "46/46 [==============================] - 7s 149ms/step - loss: 0.4643 - accuracy: 0.9452 - val_loss: 10.2380 - val_accuracy: 0.1682\n",
            "Epoch 62/100\n",
            "46/46 [==============================] - 8s 177ms/step - loss: 0.4249 - accuracy: 0.9511 - val_loss: 10.2300 - val_accuracy: 0.1601\n",
            "Epoch 63/100\n",
            "46/46 [==============================] - 7s 142ms/step - loss: 0.4014 - accuracy: 0.9559 - val_loss: 10.2621 - val_accuracy: 0.1640\n",
            "Epoch 64/100\n",
            "46/46 [==============================] - 7s 155ms/step - loss: 0.3789 - accuracy: 0.9595 - val_loss: 10.3023 - val_accuracy: 0.1645\n",
            "Epoch 65/100\n",
            "46/46 [==============================] - 7s 141ms/step - loss: 0.3555 - accuracy: 0.9630 - val_loss: 10.3140 - val_accuracy: 0.1601\n",
            "Epoch 66/100\n",
            "46/46 [==============================] - 7s 153ms/step - loss: 0.3332 - accuracy: 0.9663 - val_loss: 10.3305 - val_accuracy: 0.1607\n",
            "Epoch 67/100\n",
            "46/46 [==============================] - 7s 142ms/step - loss: 0.3134 - accuracy: 0.9691 - val_loss: 10.3600 - val_accuracy: 0.1626\n",
            "Epoch 68/100\n",
            "46/46 [==============================] - 7s 155ms/step - loss: 0.2964 - accuracy: 0.9714 - val_loss: 10.4004 - val_accuracy: 0.1630\n",
            "Epoch 69/100\n",
            "46/46 [==============================] - 7s 154ms/step - loss: 0.2783 - accuracy: 0.9745 - val_loss: 10.4617 - val_accuracy: 0.1655\n",
            "Epoch 70/100\n",
            "46/46 [==============================] - 6s 140ms/step - loss: 0.2631 - accuracy: 0.9767 - val_loss: 10.4578 - val_accuracy: 0.1655\n",
            "Epoch 71/100\n",
            "46/46 [==============================] - 7s 156ms/step - loss: 0.2566 - accuracy: 0.9771 - val_loss: 10.4825 - val_accuracy: 0.1657\n",
            "Epoch 72/100\n",
            "46/46 [==============================] - 6s 138ms/step - loss: 0.2343 - accuracy: 0.9809 - val_loss: 10.5520 - val_accuracy: 0.1680\n",
            "Epoch 73/100\n",
            "46/46 [==============================] - 7s 155ms/step - loss: 0.2214 - accuracy: 0.9826 - val_loss: 10.5482 - val_accuracy: 0.1651\n",
            "Epoch 74/100\n",
            "46/46 [==============================] - 6s 139ms/step - loss: 0.2076 - accuracy: 0.9842 - val_loss: 10.5601 - val_accuracy: 0.1626\n",
            "Epoch 75/100\n",
            "46/46 [==============================] - 7s 155ms/step - loss: 0.1954 - accuracy: 0.9858 - val_loss: 10.5923 - val_accuracy: 0.1636\n",
            "Epoch 76/100\n",
            "46/46 [==============================] - 7s 142ms/step - loss: 0.1839 - accuracy: 0.9873 - val_loss: 10.6108 - val_accuracy: 0.1617\n",
            "Epoch 77/100\n",
            "46/46 [==============================] - 7s 149ms/step - loss: 0.1743 - accuracy: 0.9882 - val_loss: 10.6241 - val_accuracy: 0.1620\n",
            "Epoch 78/100\n",
            "46/46 [==============================] - 8s 176ms/step - loss: 0.1640 - accuracy: 0.9892 - val_loss: 10.6498 - val_accuracy: 0.1617\n",
            "Epoch 79/100\n",
            "46/46 [==============================] - 7s 142ms/step - loss: 0.1544 - accuracy: 0.9900 - val_loss: 10.6797 - val_accuracy: 0.1611\n",
            "Epoch 80/100\n",
            "46/46 [==============================] - 7s 156ms/step - loss: 0.1462 - accuracy: 0.9911 - val_loss: 10.7114 - val_accuracy: 0.1628\n",
            "Epoch 81/100\n",
            "46/46 [==============================] - 6s 140ms/step - loss: 0.1380 - accuracy: 0.9920 - val_loss: 10.7552 - val_accuracy: 0.1645\n",
            "Epoch 82/100\n",
            "46/46 [==============================] - 8s 182ms/step - loss: 0.1301 - accuracy: 0.9923 - val_loss: 10.8032 - val_accuracy: 0.1674\n",
            "Epoch 83/100\n",
            "46/46 [==============================] - 8s 171ms/step - loss: 0.1223 - accuracy: 0.9932 - val_loss: 10.8722 - val_accuracy: 0.1696\n",
            "Epoch 84/100\n",
            "46/46 [==============================] - 7s 141ms/step - loss: 0.1160 - accuracy: 0.9935 - val_loss: 10.8866 - val_accuracy: 0.1686\n",
            "Epoch 85/100\n",
            "46/46 [==============================] - 7s 157ms/step - loss: 0.1095 - accuracy: 0.9939 - val_loss: 10.9073 - val_accuracy: 0.1690\n",
            "Epoch 86/100\n",
            "46/46 [==============================] - 6s 140ms/step - loss: 0.1036 - accuracy: 0.9941 - val_loss: 10.9235 - val_accuracy: 0.1686\n",
            "Epoch 87/100\n",
            "46/46 [==============================] - 7s 152ms/step - loss: 0.0975 - accuracy: 0.9945 - val_loss: 10.9174 - val_accuracy: 0.1653\n",
            "Epoch 88/100\n",
            "46/46 [==============================] - 6s 140ms/step - loss: 0.0920 - accuracy: 0.9949 - val_loss: 10.9433 - val_accuracy: 0.1657\n",
            "Epoch 89/100\n",
            "46/46 [==============================] - 7s 151ms/step - loss: 0.0869 - accuracy: 0.9952 - val_loss: 10.9624 - val_accuracy: 0.1651\n",
            "Epoch 90/100\n",
            "46/46 [==============================] - 7s 149ms/step - loss: 0.0821 - accuracy: 0.9953 - val_loss: 10.9887 - val_accuracy: 0.1674\n",
            "Epoch 91/100\n",
            "46/46 [==============================] - 7s 143ms/step - loss: 0.0772 - accuracy: 0.9958 - val_loss: 11.0280 - val_accuracy: 0.1701\n",
            "Epoch 92/100\n",
            "46/46 [==============================] - 7s 160ms/step - loss: 0.0731 - accuracy: 0.9960 - val_loss: 11.0503 - val_accuracy: 0.1699\n",
            "Epoch 93/100\n",
            "46/46 [==============================] - 6s 138ms/step - loss: 0.0688 - accuracy: 0.9963 - val_loss: 11.0697 - val_accuracy: 0.1707\n",
            "Epoch 94/100\n",
            "46/46 [==============================] - 7s 155ms/step - loss: 0.0651 - accuracy: 0.9966 - val_loss: 11.0626 - val_accuracy: 0.1692\n",
            "Epoch 95/100\n",
            "46/46 [==============================] - 7s 141ms/step - loss: 0.0618 - accuracy: 0.9967 - val_loss: 11.0589 - val_accuracy: 0.1690\n",
            "Epoch 96/100\n",
            "46/46 [==============================] - 7s 153ms/step - loss: 0.0587 - accuracy: 0.9967 - val_loss: 11.0617 - val_accuracy: 0.1674\n",
            "Epoch 97/100\n",
            "46/46 [==============================] - 7s 144ms/step - loss: 0.0557 - accuracy: 0.9969 - val_loss: 11.0735 - val_accuracy: 0.1669\n",
            "Epoch 98/100\n",
            "46/46 [==============================] - 7s 152ms/step - loss: 0.0531 - accuracy: 0.9970 - val_loss: 11.0948 - val_accuracy: 0.1663\n",
            "Epoch 99/100\n",
            "46/46 [==============================] - 8s 175ms/step - loss: 0.0507 - accuracy: 0.9971 - val_loss: 11.1231 - val_accuracy: 0.1676\n",
            "Epoch 100/100\n",
            "46/46 [==============================] - 6s 140ms/step - loss: 0.0483 - accuracy: 0.9972 - val_loss: 11.1532 - val_accuracy: 0.1682\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7844cff336d0>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
        "                    steps_per_epoch = train_samples/batch_size,\n",
        "                    epochs=100,\n",
        "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
        "                    validation_steps = val_samples/batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
        "k=-1"
      ],
      "metadata": {
        "id": "T45r3cQ1eQKT"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the input sequence to get the \"thought vectors\"\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ],
      "metadata": {
        "id": "q1KuaIjBeSP6"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_token_index['START_']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '_END' or\n",
        "           len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "daGzjLbheURa"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjCQjgrXeWlQ",
        "outputId": "cedc5fe5-b57f-4c50-c840-ce37c95c89cc"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "Input English sentence: a momentary spasmodic contraction of a muscle fiber\n",
            "Actual Hindi Translation:  मांसपेशी फाइबर का एक क्षणिक अकड़नेवाला संकुचन। \n",
            "Predicted Hindi Translation:  मांसपेशी फाइबर का एक क्षणिक अकड़नेवाला संकुचन। \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DSlGGRJeajb",
        "outputId": "94f1a5ac-de53-4257-ff46-51911a25a45f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Input English sentence: emanuele tamponi\n",
            "Actual Hindi Translation:  एमेनुएल ताम्पोनी \n",
            "Predicted Hindi Translation:  एमेनुएल ताम्पोनी \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mezxdPCxegYc",
        "outputId": "c721fd40-cfe8-42aa-e524-455e19e2e79a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Input English sentence: and b i don t even hang out with people like that\n",
            "Actual Hindi Translation:  और दूसरी बातः मैं ऐसे लोगों से दोस्ती भी नहीं रखती। \n",
            "Predicted Hindi Translation:  और दूसरी बातः मैं ऐसे लोगों से दोस्ती भी नहीं र\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMD6+MZx7JwnhlMaUEwU7AE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}